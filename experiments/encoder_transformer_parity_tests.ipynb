{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the enconder-only model\n",
    "\n",
    "In this model, we use the k-sparse parity dataset (deterministic) to test the encoder-only Transformer.\n",
    "\n",
    "**Report**: \n",
    "\n",
    "- For $n=4$, $k=2$, encoder got $100\\%$ using the parameters below. With the same parameters, the decoder got $100\\%$ as well.\n",
    "- For $n=40$, $k=4$, with the same parameters, the encoder got $52\\%$\n",
    "- New experiments: increasing the size of the data, the architecture, and the number of epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 15:42:20,497\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-07-22 15:42:20,839\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ray import tune\n",
    "\n",
    "from mindreadingautobots.sequence_generators import make_datasets\n",
    "from mindreadingautobots.models import decoder_transformer, hyperparameters\n",
    "\n",
    "# DATA LOADING\n",
    "seed = 334\n",
    "n_train = 20000\n",
    "n_data = int(n_train * 5/4) # downstream we have a 80/20 train/val split\n",
    "n = 40\n",
    "k = 4\n",
    "p_bitflip = 0.0\n",
    "raw_data = make_datasets.sparse_parity_k_n(n, k, n_data, p_bitflip)\n",
    "\n",
    "config = {\"epochs\": 40,\n",
    "        \"batch_size\": 32,\n",
    "        \"device\": torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\"), # NOTE: this is only for mac. For windows use cuda instead of mps.\n",
    "        \"lr\": 1e-3,\n",
    "        \"context_size\": 500,\n",
    "        \"vocab_size\": 2,\n",
    "        \"n_layer\": 4,\n",
    "        \"n_head\": 4,\n",
    "        \"d_model\": 16,\n",
    "        \"dropout\": 0.0,\n",
    "        \"d_ff\": 128,\n",
    "        \"activation\": \"relu\",\n",
    "        \"standard_positional_encoding\": False,\n",
    "        \"loss_type\": \"cross_entropy\",\n",
    "        \"bias\": True,\n",
    "        \"tie_weights\": False,\n",
    "        \"embedding\": \"embedding\",\n",
    "        \"mode\": \"encoder\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/Documents/PhD Projects/Transformers/exploratory_notebooks/mindreadingautobots/src/mindreadingautobots/models/decoder_transformer.py:204: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(sample[:-shift_step])\n",
      "/Users/ben/Documents/PhD Projects/Transformers/exploratory_notebooks/mindreadingautobots/src/mindreadingautobots/models/decoder_transformer.py:205: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(sample[shift_step:])\n",
      "/Users/ben/anaconda3/envs/pytorch-gpu/lib/python3.9/site-packages/ray/train/_internal/session.py:651: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.17602567699849606, val loss: 0.02089956253292454\n",
      "Epoch 1, train loss: 0.01883792527318001, val loss: 0.018057114652292743\n",
      "Epoch 2, train loss: 0.017991875100135803, val loss: 0.01799545001689416\n",
      "Epoch 3, train loss: 0.01791250951886177, val loss: 0.017914207533571373\n",
      "Epoch 4, train loss: 0.020131711181998253, val loss: 0.01804883519460441\n",
      "Epoch 5, train loss: 0.017911969393491746, val loss: 0.017978901518093553\n",
      "Epoch 6, train loss: 0.017857039558887483, val loss: 0.017970495270031275\n",
      "Epoch 7, train loss: 0.01785421078503132, val loss: 0.01788157969713211\n",
      "Epoch 8, train loss: 0.017914129328727723, val loss: 0.017958788141892973\n",
      "Epoch 9, train loss: 0.01784638808965683, val loss: 0.018296154429483565\n",
      "Epoch 10, train loss: 0.018843798154592514, val loss: 0.01786307674969078\n",
      "Epoch 11, train loss: 0.017843603318929674, val loss: 0.017902180825354188\n",
      "Epoch 12, train loss: 0.017826000770926477, val loss: 0.017802598951443746\n",
      "Epoch 13, train loss: 0.01784628832936287, val loss: 0.017793839690601748\n",
      "Epoch 14, train loss: 0.01785108377337456, val loss: 0.01779837137574603\n",
      "Epoch 15, train loss: 0.01783296754360199, val loss: 0.017851759258444143\n",
      "Epoch 16, train loss: 0.01879350306391716, val loss: 0.017838612353061414\n",
      "Epoch 17, train loss: 0.01781500650346279, val loss: 0.017816122917897383\n",
      "Epoch 18, train loss: 0.017820953659713267, val loss: 0.017982333103657527\n",
      "Epoch 19, train loss: 0.010530516430735588, val loss: 0.032358860140251126\n",
      "Epoch 20, train loss: 0.005700290786712139, val loss: 1.0085269463694192e-05\n",
      "Epoch 21, train loss: 4.372842028169543e-06, val loss: 2.2409743649543876e-06\n",
      "Epoch 22, train loss: 1.5739159035547344e-06, val loss: 1.1600062689206767e-06\n",
      "Epoch 23, train loss: 9.052507652995701e-07, val loss: 7.297359498100313e-07\n",
      "Epoch 24, train loss: 6.001124546401115e-07, val loss: 5.03303766301461e-07\n",
      "Epoch 25, train loss: 4.2282940958102697e-07, val loss: 3.604749925760849e-07\n",
      "Epoch 26, train loss: 3.0906415381650733e-07, val loss: 2.6868376441488165e-07\n",
      "Epoch 27, train loss: 2.373980282982302e-07, val loss: 2.1113508681236263e-07\n",
      "Epoch 28, train loss: 1.8566902883776494e-07, val loss: 1.5960436629791346e-07\n",
      "Epoch 29, train loss: 1.297390301147061e-07, val loss: 1.0029798346703542e-07\n",
      "Epoch 30, train loss: 7.7520823526811e-08, val loss: 5.980292914803434e-08\n",
      "Epoch 31, train loss: 4.7383530383626746e-08, val loss: 3.714944359494381e-08\n",
      "Epoch 32, train loss: 2.9725433083171994e-08, val loss: 2.3692051926826744e-08\n",
      "Epoch 33, train loss: 1.929753121601152e-08, val loss: 1.581620004108885e-08\n",
      "Epoch 34, train loss: 1.2953918319880131e-08, val loss: 1.082177179573298e-08\n",
      "Epoch 35, train loss: 8.826834522324134e-09, val loss: 7.443276656032237e-09\n",
      "Epoch 36, train loss: 6.1570055709836426e-09, val loss: 5.232926875967086e-09\n",
      "Epoch 37, train loss: 4.359849562618479e-09, val loss: 3.733806980513654e-09\n",
      "Epoch 38, train loss: 3.0997466984317156e-09, val loss: 2.6928190562023718e-09\n",
      "Epoch 39, train loss: 2.2217246401723402e-09, val loss: 1.8684246913271026e-09\n"
     ]
    }
   ],
   "source": [
    "model, train_dataloader, val_dataloader = decoder_transformer.train_loop(config, raw_data, verbose=True, \n",
    "                                                                         return_model=True, return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_token(model, token_seq, config, max_new_tokens=1):\n",
    "    model.eval()\n",
    "    for _ in range(max_new_tokens):\n",
    "        # if the sequence context is growing too long we must crop it at context_size\n",
    "        token_seq_cond = token_seq if token_seq.size(1) <= config[\"context_size\"] else token_seq[:, -config[\"context_size\"]:]\n",
    "        # forward the model to get the logits for the index in the sequence\n",
    "        logits, _ = model(token_seq_cond)\n",
    "        token_seq_next = torch.argmax(logits, dim=-1)\n",
    "        # append sampled index to the running sequence and continue\n",
    "        token_seq = torch.cat((token_seq, token_seq_next), dim=1)\n",
    "\n",
    "    return token_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples on the validation dataset: 5000\n",
      "Last token accuracy: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "for batch in val_dataloader:\n",
    "    X, y = batch\n",
    "    X = X.to(config[\"device\"])\n",
    "    y = y.to(config[\"device\"])\n",
    "    y_pred = generate_next_token(model, X, config, max_new_tokens=1)\n",
    "    correct += (y_pred[:,-1] == y[:,-1]).sum().item()\n",
    "    total += y.shape[0]\n",
    "    \n",
    "print(\"Number of samples on the validation dataset:\", len(val_dataloader.dataset))\n",
    "print(f\"Last token accuracy: {round(100*correct/total, 2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
