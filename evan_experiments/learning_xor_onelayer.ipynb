{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import deterministic.py using local file path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchdistill.core.forward_hook import ForwardHookManager\n",
    "\n",
    "sys.path.append('../sequence_generators')\n",
    "import deterministic\n",
    "sys.path.append('../ucan')\n",
    "import ucan\n",
    "import ucan_transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UCAN dataset\n",
    "\n",
    "The UCAN dataset has inputs $(Y \\oplus \\Gamma, \\Delta)$, targets $Y$, and 'hidden variable' $\\Gamma$, all of which are length-n bitstrings. Note that I'm changing my notation from whats in the writeup to match input/target sequence labels better.\n",
    "\n",
    "This has to be done in a few steps:\n",
    "1. Generate a dataset for $Y$, array $(n_{data}, n)$\n",
    "2. Generate a matched dataset $(\\Gamma, \\Delta)$, array $(N, n, 2)$ for whatever version of UCAN\n",
    "3. Compose and discard, i.e. $X = Y \\oplus \\Gamma$, data = $[Z, \\Delta]$ array $(N, 2n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data:  torch.Size([4, 2])\n",
      "Shape of output data:  torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Get a deterministic set of sequences of length N_BITS\n",
    "# with the sos and eos tokens, this becomes length 2 + 2N_BITS\n",
    "# This is why the number of bits looks funny\n",
    "data = [[0,0], [0,1], [1,0], [1,1]]\n",
    "X = np.array(data, dtype=np.int32)\n",
    "Y = np.array([(2, 0), (2, 1), (2, 1), (2, 0)], dtype=np.int32)\n",
    "\n",
    "data = torch.tensor(X).type(torch.LongTensor) # (n_data, 2)\n",
    "targets = torch.tensor(Y).type(torch.LongTensor) # (n_data)\n",
    "\n",
    "print(\"Shape of input data: \", data.shape)\n",
    "print(\"Shape of output data: \", targets.shape)\n",
    "\n",
    "train_data = data\n",
    "train_targets = targets\n",
    "\n",
    "batch_size = 4 \n",
    "def get_batch(split):\n",
    "    return train_data.to(DEVICE), train_targets.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training deck\n",
    "\n",
    "num_encoder_layers = 1\n",
    "num_decoder_layers = 1\n",
    "emb_size = 2\n",
    "nhead = 1\n",
    "src_vocab_size = 2\n",
    "tgt_vocab_size = 3\n",
    "dim_feedforward = 2\n",
    "# For deterministic task, dropout doesn't make sense\n",
    "dropout = 0.0\n",
    "\n",
    "# hyperparameters\n",
    "eval_iters = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Train loop\n",
    "eval_interval = 200\n",
    "max_iters = 20000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\Desktop\\projects\\MindReadingAutobot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ucan_transformer.Seq2SeqTransformer(\n",
    "    num_encoder_layers, \n",
    "    num_decoder_layers, \n",
    "    emb_size, \n",
    "    nhead, \n",
    "    src_vocab_size, \n",
    "    tgt_vocab_size, \n",
    "    dim_feedforward, \n",
    "    positional_encoding=False,\n",
    "    norm_first=False,\n",
    "    dropout=dropout\n",
    ").to(DEVICE)\n",
    "# `forward` signature: (src, trg, src_mask, tgt_mask, **kwargs)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "z = 1e5 # large number.\n",
    "# Using the names of parameters in the above output:\n",
    "# set the decoder linear bias to zero, and linear weights to identity\n",
    "# and disable the learning of these parameters\n",
    "for name, param in model.named_parameters():\n",
    "\n",
    "    # set the encoder query and key matrices to all ones and disable learning\n",
    "    # ENCODER SELF-ATTENTION MODIFICATIONS\n",
    "    if name == 'src_tok_emb.embedding.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        param[0,0] = 1 / np.sqrt(2)\n",
    "        param[1,1] = 1 / np.sqrt(2)\n",
    "        \n",
    "    if name == 'transformer.encoder.layers.0.self_attn.in_proj_weight':\n",
    "        param.requires_grad = False\n",
    "        assert model.transformer.encoder.layers[0].self_attn._qkv_same_embed_dim\n",
    "\n",
    "        W_q = z*np.array([[0, 1], [1, 0]])\n",
    "        W_k = np.eye(2)\n",
    "        # W_v = np.arange(4).reshape((2,2)).T\n",
    "        W_v = np.eye(2)\n",
    "\n",
    "        param[:2] = torch.tensor(W_q, dtype=torch.float32).to(DEVICE)      \n",
    "        param[2:2*2] = torch.tensor(W_k, dtype=torch.float32).to(DEVICE)     \n",
    "        param[2*2:] = torch.tensor(W_v.T, dtype=torch.float32).to(DEVICE)    \n",
    "\n",
    "    if name == 'transformer.encoder.layers.0.self_attn.in_proj_bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    # set the encoder out_proj_weight to identity and disable learning\n",
    "    if name == 'transformer.encoder.layers.0.self_attn.out_proj.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        param[0,0] = 1\n",
    "        param[1,1] = 1\n",
    "    # set the encoder out_proj_bias to zero and disable learning\n",
    "    if name == 'transformer.encoder.layers.0.self_attn.out_proj.bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    \n",
    "    # ENCODER FFN MODIFICATIONS\n",
    "    # Set the encoder linear weights to identity and disable learning\n",
    "    if name == 'transformer.encoder.layers.0.linear1.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        param[0,0] = 1\n",
    "        param[1,1] = 1\n",
    "\n",
    "    # set the encoder linear bias to zero and disable learning\n",
    "    if name == 'transformer.encoder.layers.0.linear1.bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    # set the encoder linear2 weight to ((100, 0), (100, 0)) and disable learning\n",
    "    if name == 'transformer.encoder.layers.0.linear2.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        # NOTE: The weights are transposed in defintiion of Linear\n",
    "        param[0,0] = z\n",
    "        param[0,1] = z\n",
    "    # set the encoder linear2 bias to zero and disable learning\n",
    "    if name == 'transformer.encoder.layers.0.linear2.bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        param[0] = -z/2\n",
    "    \n",
    "    # DECODER SELF-ATTENTION MODIFICATIONS\n",
    "    # set decoder embedding to identity and disable learning\n",
    "    if name == 'tgt_tok_emb.embedding.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    if name == 'transformer.decoder.layers.0.self_attn.in_proj_weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    if name == 'transformer.decoder.layers.0.self_attn.in_proj_bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    # set decoder out_proj_weight to identity and disable learning\n",
    "    if name == 'transformer.decoder.layers.0.self_attn.out_proj.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        param[0,0] = 1\n",
    "        param[1,1] = 1\n",
    "    # set decoder out_proj_bias to zero and disable learning\n",
    "    if name == 'transformer.decoder.layers.0.self_attn.out_proj.bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    if name == 'transformer.decoder.layers.0.linear1.bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    if name == 'transformer.decoder.layers.0.linear1.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        param[0,0] = 1\n",
    "        param[1,1] = 1\n",
    "\n",
    "    # set the multihead attention in_proj_weight to ((100, 0), (100, 0)) and disable learning\n",
    "    if name == 'transformer.decoder.layers.0.multihead_attn.in_proj_weight':\n",
    "        param.requires_grad = False\n",
    "        W_q = np.zeros((2, 2))\n",
    "        W_k = np.zeros((2, 2))\n",
    "        W_v = np.eye(2)\n",
    "\n",
    "        param[:2] = torch.tensor(W_q, dtype=torch.float32).to(DEVICE)      \n",
    "        param[2:2*2] = torch.tensor(W_k, dtype=torch.float32).to(DEVICE)     \n",
    "        param[2*2:] = torch.tensor(W_v.T, dtype=torch.float32).to(DEVICE)    \n",
    "\n",
    "    if name == 'transformer.decoder.layers.0.linear2.bias':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "    if name == 'transformer.decoder.layers.0.linear2.weight':\n",
    "        param.requires_grad = False\n",
    "        param.fill_(0)\n",
    "        param[0,0] = 1\n",
    "        param[1,1] = 1\n",
    "\n",
    "# Assuming you have a model called 'model'\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params}\")\n",
    "\n",
    "# transformer.decoder.layers.0.self_attn.in_proj_weight False\n",
    "# transformer.decoder.layers.0.self_attn.in_proj_bias False\n",
    "# transformer.decoder.layers.0.self_attn.out_proj.weight True\n",
    "# transformer.decoder.layers.0.self_attn.out_proj.bias True\n",
    "# transformer.decoder.layers.0.multihead_attn.in_proj_weight True\n",
    "# transformer.decoder.layers.0.multihead_attn.in_proj_bias True\n",
    "# transformer.decoder.layers.0.multihead_attn.out_proj.weight True\n",
    "# transformer.decoder.layers.0.multihead_attn.out_proj.bias True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0])\n",
      "tensor([0])\n",
      "generator\n",
      "INPUTS tensor([[[ 1.0000, -1.0000]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.6604, -0.1675,  0.0343]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "\n",
      "tensor([0, 1])\n",
      "tensor([1])\n",
      "generator\n",
      "INPUTS tensor([[[-1.0000,  1.0000]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.6125,  0.0721,  1.2094]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "\n",
      "tensor([1, 0])\n",
      "tensor([1])\n",
      "generator\n",
      "INPUTS tensor([[[-1.0000,  1.0000]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.6125,  0.0721,  1.2094]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "\n",
      "tensor([1, 1])\n",
      "tensor([0])\n",
      "generator\n",
      "INPUTS tensor([[[ 1.0000, -1.0000]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.6604, -0.1675,  0.0343]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "tgt_mask = ucan_transformer.generate_square_subsequent_mask(1, device=DEVICE)\n",
    "src_mask = None\n",
    "split = 'train'\n",
    "X, Y = get_batch(split)\n",
    "tgt_input = Y[:, :-1]\n",
    "tgt_out = Y[:, 1:]\n",
    "\n",
    "\n",
    "forward_hook_manager = ForwardHookManager(DEVICE)\n",
    "ENC_HOOKS = [\n",
    "    'src_tok_emb.embedding',\n",
    "    'transformer.encoder.layers.0.self_attn',\n",
    "    'transformer.encoder.layers.0.norm1',\n",
    "    'transformer.encoder.layers.0.linear1',\n",
    "    'transformer.encoder.layers.0.linear2',\n",
    "    'transformer.encoder.layers.0.norm2',\n",
    "]\n",
    "\n",
    "DEC_HOOKS = [\n",
    "    'transformer.decoder.layers.0.self_attn',\n",
    "    'transformer.decoder.layers.0.norm1',\n",
    "    'transformer.decoder.layers.0.multihead_attn',\n",
    "    'transformer.decoder.layers.0.norm2',\n",
    "    'transformer.decoder.layers.0.linear1',\n",
    "    'transformer.decoder.layers.0.linear2',\n",
    "    'generator'\n",
    "]\n",
    "for hook in ENC_HOOKS + DEC_HOOKS:\n",
    "    forward_hook_manager.add_hook(model, hook, requires_input=True, requires_output=True)\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    # if i != 1:\n",
    "    #     continue\n",
    "    x = X[i,:]\n",
    "    # run the model and sink the hooks\n",
    "    output = model(x, tgt_input[i], src_mask, tgt_mask)\n",
    "    io_dict = forward_hook_manager.pop_io_dict()\n",
    "    assert(torch.equal(x, io_dict.get('src_tok_emb.embedding').get('input')))\n",
    "\n",
    "    print(x)    \n",
    "    print(tgt_out[i])\n",
    "    # for hook in ENC_HOOKS:\n",
    "    #     print(hook)\n",
    "    #     # print(io_dict.get(hook).get('input'))\n",
    "    #     print(io_dict.get(hook).get('output'))\n",
    "    #     print()\n",
    "    # break\n",
    "    for hook in DEC_HOOKS:\n",
    "        if hook == 'generator':\n",
    "            print(hook)\n",
    "            print(\"INPUTS\", io_dict.get(hook).get('input'))\n",
    "            print(io_dict.get(hook).get('output'))\n",
    "            print()\n",
    "\n",
    "\n",
    "    # print(activation['transformer.encoder.layers.0.self_attn.in_proj_weight'])\n",
    "    # print(activation['src_tok_emb.embedding'])\n",
    "    # print(activation['transformer.encoder.layers.0.linear1'])\n",
    "    # print(activation['transformer.encoder.layers.0.dropout1'])\n",
    "    # print(activation['transformer.encoder.layers.0.linear2'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[ 1.0000, -1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[-1.0000,  1.0000],\n",
      "        [ 1.0000, -1.0000]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Image Example\n",
    "for X in [np.array([[1, 0], [1, 0]]), np.array([[1, 0], [0, 1]]), np.array([[0, 1], [1, 0]]), np.array([[0, 1], [0, 1]])]:\n",
    "    X = torch.tensor(X, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "    # Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
    "    # as shown in the image below\n",
    "    layer_norm = torch.nn.LayerNorm([2, 2])\n",
    "    output = layer_norm(X + X)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_src_mask(n):\n",
    "    return None\n",
    "\n",
    "N_BITS = 1\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(verbose=False):\n",
    "    # Average the loss over many batches. Hardcoded cross_entropy loss\n",
    "    # Needs to be in same namespace as model and get_batch\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    tgt_mask = ucan_transformer.generate_square_subsequent_mask(N_BITS, device=DEVICE)\n",
    "    src_mask = make_src_mask(N_BITS)\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            tgt_input = Y[:, :-1]\n",
    "            tgt_out = Y[:, 1:]\n",
    "            logits = model(X, tgt_input, src_mask, tgt_mask)\n",
    "\n",
    "            if verbose:\n",
    "                preds = torch.argmax(logits.reshape(batch_size, N_BITS, tgt_vocab_size), dim=2)\n",
    "                for i in range(len(X)):\n",
    "                    print(f\"input: {X[i]}\")\n",
    "                    print(f\"target: {tgt_out[i]}\")\n",
    "                    print(f\"predicted: {preds[i]}\")\n",
    "                    print(logits.reshape(batch_size, N_BITS, tgt_vocab_size)[i])\n",
    "                    print()\n",
    "            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0000, -1.0000],\n",
      "         [ 1.0000, -1.0000]],\n",
      "\n",
      "        [[-1.0000,  1.0000],\n",
      "         [-1.0000,  1.0000]],\n",
      "\n",
      "        [[-1.0000,  1.0000],\n",
      "         [-1.0000,  1.0000]],\n",
      "\n",
      "        [[ 1.0000, -1.0000],\n",
      "         [ 1.0000, -1.0000]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "step 0: train loss 1.5329, val loss 1.5329\n",
      "step 200: train loss 1.4484, val loss 1.4484\n",
      "step 400: train loss 1.3673, val loss 1.3673\n",
      "step 600: train loss 1.2893, val loss 1.2893\n",
      "step 800: train loss 1.2143, val loss 1.2143\n",
      "step 1000: train loss 1.1423, val loss 1.1423\n",
      "step 1200: train loss 1.0733, val loss 1.0733\n",
      "step 1400: train loss 1.0070, val loss 1.0070\n",
      "step 1600: train loss 0.9436, val loss 0.9436\n",
      "step 1800: train loss 0.8828, val loss 0.8828\n",
      "step 2000: train loss 0.8247, val loss 0.8247\n",
      "step 2200: train loss 0.7693, val loss 0.7693\n",
      "step 2400: train loss 0.7164, val loss 0.7164\n",
      "step 2600: train loss 0.6660, val loss 0.6660\n",
      "step 2800: train loss 0.6182, val loss 0.6182\n",
      "step 3000: train loss 0.5728, val loss 0.5728\n",
      "step 3200: train loss 0.5298, val loss 0.5298\n",
      "step 3400: train loss 0.4891, val loss 0.4891\n",
      "step 3600: train loss 0.4507, val loss 0.4507\n",
      "step 3800: train loss 0.4145, val loss 0.4145\n",
      "step 4000: train loss 0.3805, val loss 0.3805\n",
      "step 4200: train loss 0.3487, val loss 0.3487\n",
      "step 4400: train loss 0.3189, val loss 0.3189\n",
      "step 4600: train loss 0.2913, val loss 0.2913\n",
      "step 4800: train loss 0.2657, val loss 0.2657\n",
      "step 5000: train loss 0.2421, val loss 0.2421\n",
      "step 5200: train loss 0.2204, val loss 0.2204\n",
      "step 5400: train loss 0.2005, val loss 0.2005\n",
      "step 5600: train loss 0.1823, val loss 0.1823\n",
      "step 5800: train loss 0.1656, val loss 0.1656\n",
      "step 6000: train loss 0.1505, val loss 0.1505\n",
      "step 6200: train loss 0.1367, val loss 0.1367\n",
      "step 6400: train loss 0.1241, val loss 0.1241\n",
      "step 6600: train loss 0.1127, val loss 0.1127\n",
      "step 6800: train loss 0.1023, val loss 0.1023\n",
      "step 7000: train loss 0.0929, val loss 0.0929\n",
      "step 7200: train loss 0.0843, val loss 0.0843\n",
      "step 7400: train loss 0.0765, val loss 0.0765\n",
      "step 7600: train loss 0.0695, val loss 0.0695\n",
      "step 7800: train loss 0.0631, val loss 0.0631\n",
      "step 8000: train loss 0.0573, val loss 0.0573\n",
      "step 8200: train loss 0.0521, val loss 0.0521\n",
      "step 8400: train loss 0.0473, val loss 0.0473\n",
      "step 8600: train loss 0.0430, val loss 0.0430\n",
      "step 8800: train loss 0.0391, val loss 0.0391\n",
      "step 9000: train loss 0.0355, val loss 0.0355\n",
      "step 9200: train loss 0.0323, val loss 0.0323\n",
      "step 9400: train loss 0.0293, val loss 0.0293\n",
      "step 9600: train loss 0.0267, val loss 0.0267\n",
      "step 9800: train loss 0.0242, val loss 0.0242\n",
      "step 10000: train loss 0.0220, val loss 0.0220\n",
      "step 10200: train loss 0.0200, val loss 0.0200\n",
      "step 10400: train loss 0.0182, val loss 0.0182\n",
      "step 10600: train loss 0.0166, val loss 0.0166\n",
      "step 10800: train loss 0.0151, val loss 0.0151\n",
      "step 11000: train loss 0.0137, val loss 0.0137\n",
      "step 11200: train loss 0.0125, val loss 0.0125\n",
      "step 11400: train loss 0.0114, val loss 0.0114\n",
      "step 11600: train loss 0.0103, val loss 0.0103\n",
      "step 11800: train loss 0.0094, val loss 0.0094\n",
      "step 12000: train loss 0.0086, val loss 0.0086\n",
      "step 12200: train loss 0.0078, val loss 0.0078\n",
      "step 12400: train loss 0.0071, val loss 0.0071\n",
      "step 12600: train loss 0.0064, val loss 0.0064\n",
      "step 12800: train loss 0.0059, val loss 0.0059\n",
      "step 13000: train loss 0.0053, val loss 0.0053\n",
      "step 13200: train loss 0.0049, val loss 0.0049\n",
      "step 13400: train loss 0.0044, val loss 0.0044\n",
      "step 13600: train loss 0.0040, val loss 0.0040\n",
      "step 13800: train loss 0.0037, val loss 0.0037\n",
      "step 14000: train loss 0.0033, val loss 0.0033\n",
      "step 14200: train loss 0.0030, val loss 0.0030\n",
      "step 14400: train loss 0.0028, val loss 0.0028\n",
      "step 14600: train loss 0.0025, val loss 0.0025\n",
      "step 14800: train loss 0.0023, val loss 0.0023\n",
      "step 15000: train loss 0.0021, val loss 0.0021\n",
      "step 15200: train loss 0.0019, val loss 0.0019\n",
      "step 15400: train loss 0.0017, val loss 0.0017\n",
      "step 15600: train loss 0.0016, val loss 0.0016\n",
      "step 15800: train loss 0.0014, val loss 0.0014\n",
      "step 16000: train loss 0.0013, val loss 0.0013\n",
      "step 16200: train loss 0.0012, val loss 0.0012\n",
      "step 16400: train loss 0.0011, val loss 0.0011\n",
      "step 16600: train loss 0.0010, val loss 0.0010\n",
      "step 16800: train loss 0.0009, val loss 0.0009\n",
      "step 17000: train loss 0.0008, val loss 0.0008\n",
      "step 17200: train loss 0.0007, val loss 0.0007\n",
      "step 17400: train loss 0.0007, val loss 0.0007\n",
      "step 17600: train loss 0.0006, val loss 0.0006\n",
      "step 17800: train loss 0.0006, val loss 0.0006\n",
      "step 18000: train loss 0.0005, val loss 0.0005\n",
      "step 18200: train loss 0.0005, val loss 0.0005\n",
      "step 18400: train loss 0.0004, val loss 0.0004\n",
      "step 18600: train loss 0.0004, val loss 0.0004\n",
      "step 18800: train loss 0.0003, val loss 0.0003\n",
      "step 19000: train loss 0.0003, val loss 0.0003\n",
      "step 19200: train loss 0.0003, val loss 0.0003\n",
      "step 19400: train loss 0.0003, val loss 0.0003\n",
      "step 19600: train loss 0.0002, val loss 0.0002\n",
      "step 19800: train loss 0.0002, val loss 0.0002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "memory = model.encode(X, None)\n",
    "print(memory)\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    # we're doing that kind of sketchy off-by-one thing\n",
    "    # the input is missing the final token (it's always the EOS token....)\n",
    "    tgt_input = yb[:, :-1]\n",
    "    tgt_mask = ucan_transformer.generate_square_subsequent_mask(tgt_input.size(1), device=DEVICE)\n",
    "    src_mask = make_src_mask(N_BITS)\n",
    "    logits = model(xb, tgt_input, src_mask, tgt_mask)\n",
    "\n",
    "    # and the loss is based on the output, which is missing the first token (it's always the SOS token....)\n",
    "    tgt_out = yb[:, 1:]\n",
    "    loss = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "    loss_history.append(loss.item())\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([0, 0])\n",
      "target: tensor([0])\n",
      "predicted: tensor([0])\n",
      "tensor([[ 6.1308, -3.3359, -3.3516]])\n",
      "\n",
      "input: tensor([0, 1])\n",
      "target: tensor([1])\n",
      "predicted: tensor([1])\n",
      "tensor([[-3.1588,  6.4066, -2.2733]])\n",
      "\n",
      "input: tensor([1, 0])\n",
      "target: tensor([1])\n",
      "predicted: tensor([1])\n",
      "tensor([[-3.1588,  6.4066, -2.2733]])\n",
      "\n",
      "input: tensor([1, 1])\n",
      "target: tensor([0])\n",
      "predicted: tensor([0])\n",
      "tensor([[ 6.1308, -3.3359, -3.3516]])\n",
      "\n",
      "input: tensor([0, 0])\n",
      "target: tensor([0])\n",
      "predicted: tensor([0])\n",
      "tensor([[ 6.1308, -3.3359, -3.3516]])\n",
      "\n",
      "input: tensor([0, 1])\n",
      "target: tensor([1])\n",
      "predicted: tensor([1])\n",
      "tensor([[-3.1588,  6.4066, -2.2733]])\n",
      "\n",
      "input: tensor([1, 0])\n",
      "target: tensor([1])\n",
      "predicted: tensor([1])\n",
      "tensor([[-3.1588,  6.4066, -2.2733]])\n",
      "\n",
      "input: tensor([1, 1])\n",
      "target: tensor([0])\n",
      "predicted: tensor([0])\n",
      "tensor([[ 6.1308, -3.3359, -3.3516]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': tensor(0.0002), 'val': tensor(0.0002)}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log\n",
    "\n",
    "Enc |dec | dmodel | nhead | dim_ff | final train/val loss\n",
    "8,4,16,4,128 .21 / .16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d4138c610>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SOS_TOKEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m make_src_mask(N_BITS)\n\u001b[0;32m     37\u001b[0m memory \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(x, src_mask)\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;66;03m# now this is phi(x), shape (1, 2*N_BITS + 2, emb_dim)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m ys \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[43mSOS_TOKEN\u001b[49m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SOS_TOKEN' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# sample a batch of data\n",
    "torch.manual_seed(1337) # to get what andrej karpathy got\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "for i in range(batch_size):\n",
    "    x, y = xb[i], yb[i]\n",
    "    print(x.shape)\n",
    "    x, y = x.unsqueeze(0), y.unsqueeze(0)\n",
    "    print(x.shape)\n",
    "    break\n",
    "\n",
    "    src_mask = make_src_mask(N_BITS)\n",
    "    tgt_mask = ucan_transformer.generate_square_subsequent_mask(N_BITS + 2, device=DEVICE)\n",
    "    # evaluate the loss\n",
    "    logits = model(x, y, src_mask, tgt_mask)\n",
    "    print('logits:', logits.shape)\n",
    "    print('loss:', loss)\n",
    "\n",
    "    # sample the output from the logits\n",
    "    _, preds = torch.max(logits, dim=1)\n",
    "    print(\"x    \", x.squeeze(0))\n",
    "    print(\"logits\", logits)\n",
    "    print(\"preds\", preds)\n",
    "    print(\"y    \", y.squeeze(0))\n",
    "    print()\n",
    "\n",
    "# -----------------------------------------------\n",
    "# GENERATING SEQUENCES\n",
    "max_len = N_BITS + 2\n",
    "\n",
    "for i in range(batch_size):\n",
    "    x, y = xb[i], yb[i]\n",
    "    x, y = x.unsqueeze(0), y.unsqueeze(0)\n",
    "    src_mask = make_src_mask(N_BITS)\n",
    "\n",
    "    memory = model.encode(x, src_mask).to(DEVICE) # now this is phi(x), shape (1, 2*N_BITS + 2, emb_dim)\n",
    "    ys = torch.ones(1, 1).fill_(SOS_TOKEN).type(torch.long).to(DEVICE)\n",
    "\n",
    "\n",
    "    print(\"input\", x)\n",
    "    print(\"target\", y)\n",
    "    for i in range(max_len - 1): # -1 since we start with SOS\n",
    "        tgt_mask = (ucan_transformer.generate_square_subsequent_mask(ys.size(1), device=DEVICE).type(torch.bool)).to(DEVICE) \n",
    "        out = model.decode(tgt=ys, memory=memory, tgt_mask=tgt_mask) # (1, tgt_seq_len, emb_dim)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(x.data).fill_(next_word)], dim=1)\n",
    "        # print(out, \"out\")\n",
    "        # print(ys, \"ys\")\n",
    "        # print(prob, \"prob\")\n",
    "        # print()\n",
    "    print(\"final output\", ys)\n",
    "    print()\n",
    "\n",
    "\n",
    "# tgt_mask = (ucan_transformer.generate_square_subsequent_mask(ys.size(1), device=DEVICE).type(torch.bool)).to(DEVICE) \n",
    "\n",
    "# # This mask sets -inf to True, which is correct according to `Transformer` docs\n",
    "# i = 0\n",
    "# out = model.decode(tgt=ys, memory=memory, tgt_mask=tgt_mask) # (1, tgt_seq_len, emb_dim)\n",
    "# print(\"out.shape\", out.shape)\n",
    "# logits = model.generator(out[:, -1])\n",
    "# # logits = model.generator(out)\n",
    "# print(\"logits.shape\", logits.shape)\n",
    "\n",
    "# _, preds = torch.max(logits, dim=-1)\n",
    "# print(\"ys  \", ys)\n",
    "# print(\"pred:\", preds)\n",
    "\n",
    "# print(memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.7868,  0.3571,  0.2683, -0.3423,  0.8015,  0.9599, -0.7208,\n",
      "           0.0275,  0.1133,  0.3672, -0.5141,  1.3417],\n",
      "         [-1.1109,  0.3338,  0.3859, -1.4481, -0.9562,  2.0624,  1.2049,\n",
      "          -0.6362,  0.2811,  0.6141, -0.8774,  0.0184],\n",
      "         [-1.1241,  0.2551,  0.4137, -1.4547, -0.9476,  2.0578,  1.2247,\n",
      "          -0.6118,  0.2941,  0.6032, -0.8785,  0.0387],\n",
      "         [-1.1677,  0.2572,  0.3904, -1.4032, -0.9617,  2.0293,  1.3103,\n",
      "          -0.5942,  0.2802,  0.5733, -0.8782,  0.0352],\n",
      "         [-1.2104,  0.3464,  0.3609, -1.3546, -0.9713,  1.9936,  1.3736,\n",
      "          -0.5989,  0.2561,  0.5441, -0.8755,  0.0084],\n",
      "         [-1.9315, -0.6380,  1.4399,  0.3022,  1.0120,  0.4055, -1.1799,\n",
      "           0.0860, -0.1640,  0.7048, -1.2249,  1.0884],\n",
      "         [-1.9339, -0.5638,  1.4427,  0.2349,  1.0007,  0.4492, -1.2247,\n",
      "           0.1311, -0.1612,  0.6739, -1.2345,  1.0857],\n",
      "         [-1.1189,  0.3520,  0.4719, -1.5429, -0.8868,  2.0529,  1.1527,\n",
      "          -0.6148,  0.2778,  0.5736, -0.8794,  0.0322],\n",
      "         [-1.1117,  0.2646,  0.5001, -1.5900, -0.8689,  2.0464,  1.1558,\n",
      "          -0.5867,  0.2963,  0.5636, -0.8710,  0.0700],\n",
      "         [-1.9095, -0.5974,  1.4829, -0.0930,  1.0984,  0.4114, -1.0502,\n",
      "           0.0903, -0.2330,  0.6108, -1.1770,  1.2612],\n",
      "         [-1.9435, -0.6004,  1.4701, -0.0041,  1.0862,  0.4062, -1.0842,\n",
      "           0.1034, -0.1932,  0.6371, -1.1818,  1.1989],\n",
      "         [-1.2430,  0.3476,  0.3917, -1.4999, -0.8243,  2.0242,  1.2668,\n",
      "          -0.5913,  0.2803,  0.5179, -0.8564,  0.0545],\n",
      "         [-1.2094,  0.3929,  0.4051, -1.5551, -0.8058,  2.0320,  1.2100,\n",
      "          -0.6102,  0.2813,  0.5232, -0.8479,  0.0524],\n",
      "         [-1.1513,  0.3679,  0.4192, -1.6296, -0.8038,  2.0398,  1.1666,\n",
      "          -0.6014,  0.2920,  0.5258, -0.8384,  0.0815],\n",
      "         [-1.1365,  0.2896,  0.4380, -1.6601, -0.8011,  2.0405,  1.1583,\n",
      "          -0.5843,  0.3131,  0.5239, -0.8356,  0.1214],\n",
      "         [-1.9291, -0.5465,  1.4353, -0.0473,  1.0993,  0.4311, -1.1221,\n",
      "           0.1307, -0.1737,  0.5498, -1.1950,  1.2641],\n",
      "         [-1.2328,  0.2497,  0.3409, -1.5551, -0.7896,  2.0227,  1.2831,\n",
      "          -0.5716,  0.3177,  0.5150, -0.8404,  0.1268],\n",
      "         [-1.1644, -0.8199,  1.5520, -0.6495, -0.8009,  1.1600, -0.1977,\n",
      "           0.1803, -0.0248,  1.3462, -1.5414,  0.8374]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2]], device='cuda:0') ys\n",
      "tensor([[ 1.7953,  1.8705, -3.4646, -2.9662]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.8422,  1.6185, -3.4436, -2.9632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf, -inf],\n",
      "        [0., 0., -inf],\n",
      "        [0., 0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697],\n",
      "         [ 0.1441,  2.2480, -0.6197, -0.9697,  1.1294,  0.5845, -1.7319,\n",
      "           2.3668, -0.9564, -1.0624,  0.5569, -1.1021]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 1.7423,  2.0293, -3.6887, -2.7872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf],\n",
      "        [0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697],\n",
      "         [ 0.1441,  2.2480, -0.6197, -0.9697,  1.1294,  0.5845, -1.7319,\n",
      "           2.3668, -0.9564, -1.0624,  0.5569, -1.1021],\n",
      "         [ 0.8528,  1.4241, -0.3003, -0.1138,  0.2227,  0.7528, -2.3854,\n",
      "           2.7800, -0.7787, -1.0486,  0.0081, -1.0010]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.2520,  1.6394, -3.5942, -2.3785]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697],\n",
      "         [ 0.1441,  2.2480, -0.6197, -0.9697,  1.1294,  0.5845, -1.7319,\n",
      "           2.3668, -0.9564, -1.0624,  0.5569, -1.1021],\n",
      "         [ 0.8528,  1.4241, -0.3003, -0.1138,  0.2227,  0.7528, -2.3854,\n",
      "           2.7800, -0.7787, -1.0486,  0.0081, -1.0010],\n",
      "         [-0.2352,  0.8998, -0.2121, -0.5112,  0.6165,  0.6870, -2.3933,\n",
      "           3.1812, -0.3517, -0.5731,  0.3524, -1.1253]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.9334,  1.7536, -3.4672, -2.4327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697],\n",
      "         [ 0.1441,  2.2480, -0.6197, -0.9697,  1.1294,  0.5845, -1.7319,\n",
      "           2.3668, -0.9564, -1.0624,  0.5569, -1.1021],\n",
      "         [ 0.8528,  1.4241, -0.3003, -0.1138,  0.2227,  0.7528, -2.3854,\n",
      "           2.7800, -0.7787, -1.0486,  0.0081, -1.0010],\n",
      "         [-0.2352,  0.8998, -0.2121, -0.5112,  0.6165,  0.6870, -2.3933,\n",
      "           3.1812, -0.3517, -0.5731,  0.3524, -1.1253],\n",
      "         [ 0.4362,  1.6598, -0.9374, -1.7154,  1.5094,  0.9382, -0.9895,\n",
      "           2.4549, -0.7743, -0.5954, -0.1595, -1.2763]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 1.5140,  2.5645, -3.7196, -2.0801]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697],\n",
      "         [ 0.1441,  2.2480, -0.6197, -0.9697,  1.1294,  0.5845, -1.7319,\n",
      "           2.3668, -0.9564, -1.0624,  0.5569, -1.1021],\n",
      "         [ 0.8528,  1.4241, -0.3003, -0.1138,  0.2227,  0.7528, -2.3854,\n",
      "           2.7800, -0.7787, -1.0486,  0.0081, -1.0010],\n",
      "         [-0.2352,  0.8998, -0.2121, -0.5112,  0.6165,  0.6870, -2.3933,\n",
      "           3.1812, -0.3517, -0.5731,  0.3524, -1.1253],\n",
      "         [ 0.4362,  1.6598, -0.9374, -1.7154,  1.5094,  0.9382, -0.9895,\n",
      "           2.4549, -0.7743, -0.5954, -0.1595, -1.2763],\n",
      "         [-0.6462,  1.0183,  0.0338, -1.4558,  1.0744,  0.9041, -1.7509,\n",
      "           2.9368,  0.1237, -0.1320, -0.5279, -1.2435]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.8322,  2.2890, -3.3510, -2.0556]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697],\n",
      "         [ 0.1441,  2.2480, -0.6197, -0.9697,  1.1294,  0.5845, -1.7319,\n",
      "           2.3668, -0.9564, -1.0624,  0.5569, -1.1021],\n",
      "         [ 0.8528,  1.4241, -0.3003, -0.1138,  0.2227,  0.7528, -2.3854,\n",
      "           2.7800, -0.7787, -1.0486,  0.0081, -1.0010],\n",
      "         [-0.2352,  0.8998, -0.2121, -0.5112,  0.6165,  0.6870, -2.3933,\n",
      "           3.1812, -0.3517, -0.5731,  0.3524, -1.1253],\n",
      "         [ 0.4362,  1.6598, -0.9374, -1.7154,  1.5094,  0.9382, -0.9895,\n",
      "           2.4549, -0.7743, -0.5954, -0.1595, -1.2763],\n",
      "         [-0.6462,  1.0183,  0.0338, -1.4558,  1.0744,  0.9041, -1.7509,\n",
      "           2.9368,  0.1237, -0.1320, -0.5279, -1.2435],\n",
      "         [ 0.4092,  0.4639, -0.8515, -0.2431,  0.0593, -0.2076, -1.1747,\n",
      "           2.7772,  1.3246,  0.3161, -0.4826, -2.2395]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.8240,  0.7871, -3.7078,  0.0735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[[-0.6215,  2.6652, -0.3210, -0.9126,  0.9668,  0.4516, -1.5679,\n",
      "           2.2724, -0.7793, -1.2046,  0.5827, -0.9221],\n",
      "         [-0.3644,  2.4371, -0.2941, -0.5195,  0.6165,  0.3531, -2.0415,\n",
      "           2.3806, -0.8867, -0.9838,  0.8195, -0.9697],\n",
      "         [ 0.1441,  2.2480, -0.6197, -0.9697,  1.1294,  0.5845, -1.7319,\n",
      "           2.3668, -0.9564, -1.0624,  0.5569, -1.1021],\n",
      "         [ 0.8528,  1.4241, -0.3003, -0.1138,  0.2227,  0.7528, -2.3854,\n",
      "           2.7800, -0.7787, -1.0486,  0.0081, -1.0010],\n",
      "         [-0.2352,  0.8998, -0.2121, -0.5112,  0.6165,  0.6870, -2.3933,\n",
      "           3.1812, -0.3517, -0.5731,  0.3524, -1.1253],\n",
      "         [ 0.4362,  1.6598, -0.9374, -1.7154,  1.5094,  0.9382, -0.9895,\n",
      "           2.4549, -0.7743, -0.5954, -0.1595, -1.2763],\n",
      "         [-0.6462,  1.0183,  0.0338, -1.4558,  1.0744,  0.9041, -1.7509,\n",
      "           2.9368,  0.1237, -0.1320, -0.5279, -1.2435],\n",
      "         [ 0.4092,  0.4639, -0.8515, -0.2431,  0.0593, -0.2076, -1.1747,\n",
      "           2.7772,  1.3246,  0.3161, -0.4826, -2.2395],\n",
      "         [ 1.5561,  0.5076, -2.4817, -0.9651, -0.3973, -0.3769,  1.4353,\n",
      "           0.4173,  0.9514,  0.8456, -0.4853, -1.0076]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 0, 1, 1, 0]], device='cuda:0') ys\n",
      "tensor([[-3.5366e-04,  1.2898e-01, -2.2501e+00,  2.1610e+00]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xv, yv = get_batch('val')\n",
    "src = xv[0]\n",
    "truth = yv[0]\n",
    "\n",
    "src = src.to(DEVICE)\n",
    "src_mask = None\n",
    "max_len = 10\n",
    "\n",
    "# For a single example evaluation, we need to add a dummy batch dimension (1, *) with unsqueeze(0)\n",
    "memory = model.encode(src.unsqueeze(0), src_mask)\n",
    "# The [1, 1] shape starts us off with a dummy batch dimension \n",
    "ys = torch.ones(1, 1).fill_(SOS_TOKEN).type(torch.long).to(DEVICE)\n",
    "\n",
    "print(memory)\n",
    "\n",
    "for i in range(max_len - 1): # -1 since we start with SOS\n",
    "    memory = memory.to(DEVICE)\n",
    "    tgt_mask = (ucan_transformer.generate_square_subsequent_mask(ys.size(1), device=DEVICE)).to(DEVICE)\n",
    "    print(tgt_mask)\n",
    "    out = model.decode(tgt=ys, memory=memory, tgt_mask=tgt_mask) # (1, tgt_seq_len, emb_dim)\n",
    "\n",
    "\n",
    "    prob = model.generator(out[:, -1])\n",
    "    print(out, \"out\")\n",
    "    print(ys, \"ys\")\n",
    "    print(prob, \"prob\")\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.item()\n",
    "    ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xv_i tensor([2, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 3], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([[[-0.5963,  1.6153,  1.8461, -0.1170,  1.5781,  0.5869, -1.1237,\n",
      "          -0.3987, -0.7045, -2.1012,  0.1954, -0.7587]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2]], device='cuda:0') ys\n",
      "tensor([[ 1.9841,  2.0354, -0.7844, -2.5241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.5963,  1.6153,  1.8461, -0.1170,  1.5781,  0.5869, -1.1237,\n",
      "          -0.3987, -0.7045, -2.1012,  0.1954, -0.7587],\n",
      "         [ 0.1536,  0.5132,  1.7468,  0.0826,  2.0158, -0.1218, -1.1890,\n",
      "          -0.9465, -1.5047, -2.0150,  0.5374,  0.9175]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.3561,  2.4091, -2.6605, -1.6287]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.5963,  1.6153,  1.8461, -0.1170,  1.5781,  0.5869, -1.1237,\n",
      "          -0.3987, -0.7045, -2.1012,  0.1954, -0.7587],\n",
      "         [ 0.1536,  0.5132,  1.7468,  0.0826,  2.0158, -0.1218, -1.1890,\n",
      "          -0.9465, -1.5047, -2.0150,  0.5374,  0.9175],\n",
      "         [ 0.4186,  0.2751,  1.8131,  0.0022,  1.6174, -0.2270, -1.0423,\n",
      "          -1.1356, -1.5871, -1.9409,  0.5506,  1.4812]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.3298,  2.3269, -3.3170, -1.2850]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.5963,  1.6153,  1.8461, -0.1170,  1.5781,  0.5869, -1.1237,\n",
      "          -0.3987, -0.7045, -2.1012,  0.1954, -0.7587],\n",
      "         [ 0.1536,  0.5132,  1.7468,  0.0826,  2.0158, -0.1218, -1.1890,\n",
      "          -0.9465, -1.5047, -2.0150,  0.5374,  0.9175],\n",
      "         [ 0.4186,  0.2751,  1.8131,  0.0022,  1.6174, -0.2270, -1.0423,\n",
      "          -1.1356, -1.5871, -1.9409,  0.5506,  1.4812],\n",
      "         [ 0.9501, -0.3080,  1.9143, -0.1483,  0.8867, -0.1874, -1.0859,\n",
      "          -1.0961, -1.6832, -1.4982,  0.4141,  2.0918]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 1.9824,  2.1173, -4.0767, -0.6527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.5963,  1.6153,  1.8461, -0.1170,  1.5781,  0.5869, -1.1237,\n",
      "          -0.3987, -0.7045, -2.1012,  0.1954, -0.7587],\n",
      "         [ 0.1536,  0.5132,  1.7468,  0.0826,  2.0158, -0.1218, -1.1890,\n",
      "          -0.9465, -1.5047, -2.0150,  0.5374,  0.9175],\n",
      "         [ 0.4186,  0.2751,  1.8131,  0.0022,  1.6174, -0.2270, -1.0423,\n",
      "          -1.1356, -1.5871, -1.9409,  0.5506,  1.4812],\n",
      "         [ 0.9501, -0.3080,  1.9143, -0.1483,  0.8867, -0.1874, -1.0859,\n",
      "          -1.0961, -1.6832, -1.4982,  0.4141,  2.0918],\n",
      "         [ 0.7867, -0.0294,  1.7032,  0.0402,  1.0964, -0.4294, -0.7761,\n",
      "          -1.3463, -1.6947, -1.6382,  0.3869,  2.1547]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.0436,  2.2062, -3.9386, -0.6360]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-5.9634e-01,  1.6153e+00,  1.8461e+00, -1.1703e-01,  1.5781e+00,\n",
      "           5.8687e-01, -1.1237e+00, -3.9868e-01, -7.0449e-01, -2.1012e+00,\n",
      "           1.9538e-01, -7.5867e-01],\n",
      "         [ 1.5361e-01,  5.1322e-01,  1.7468e+00,  8.2632e-02,  2.0158e+00,\n",
      "          -1.2180e-01, -1.1890e+00, -9.4654e-01, -1.5047e+00, -2.0150e+00,\n",
      "           5.3739e-01,  9.1754e-01],\n",
      "         [ 4.1859e-01,  2.7507e-01,  1.8131e+00,  2.2498e-03,  1.6174e+00,\n",
      "          -2.2698e-01, -1.0423e+00, -1.1356e+00, -1.5871e+00, -1.9409e+00,\n",
      "           5.5064e-01,  1.4812e+00],\n",
      "         [ 9.5014e-01, -3.0804e-01,  1.9143e+00, -1.4826e-01,  8.8666e-01,\n",
      "          -1.8743e-01, -1.0859e+00, -1.0961e+00, -1.6832e+00, -1.4982e+00,\n",
      "           4.1413e-01,  2.0918e+00],\n",
      "         [ 7.8672e-01, -2.9418e-02,  1.7032e+00,  4.0243e-02,  1.0964e+00,\n",
      "          -4.2943e-01, -7.7613e-01, -1.3463e+00, -1.6947e+00, -1.6382e+00,\n",
      "           3.8687e-01,  2.1547e+00],\n",
      "         [ 9.1019e-01, -1.4873e-01,  1.6014e+00,  1.3995e-02,  6.8649e-01,\n",
      "          -4.6609e-01, -6.1476e-01, -1.4606e+00, -1.6964e+00, -1.4245e+00,\n",
      "           3.8821e-01,  2.4695e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.8821,  1.9886, -4.2026, -0.3244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-5.9634e-01,  1.6153e+00,  1.8461e+00, -1.1703e-01,  1.5781e+00,\n",
      "           5.8687e-01, -1.1237e+00, -3.9868e-01, -7.0449e-01, -2.1012e+00,\n",
      "           1.9538e-01, -7.5867e-01],\n",
      "         [ 1.5361e-01,  5.1322e-01,  1.7468e+00,  8.2632e-02,  2.0158e+00,\n",
      "          -1.2180e-01, -1.1890e+00, -9.4654e-01, -1.5047e+00, -2.0150e+00,\n",
      "           5.3739e-01,  9.1754e-01],\n",
      "         [ 4.1859e-01,  2.7507e-01,  1.8131e+00,  2.2498e-03,  1.6174e+00,\n",
      "          -2.2698e-01, -1.0423e+00, -1.1356e+00, -1.5871e+00, -1.9409e+00,\n",
      "           5.5064e-01,  1.4812e+00],\n",
      "         [ 9.5014e-01, -3.0804e-01,  1.9143e+00, -1.4826e-01,  8.8666e-01,\n",
      "          -1.8743e-01, -1.0859e+00, -1.0961e+00, -1.6832e+00, -1.4982e+00,\n",
      "           4.1413e-01,  2.0918e+00],\n",
      "         [ 7.8672e-01, -2.9418e-02,  1.7032e+00,  4.0243e-02,  1.0964e+00,\n",
      "          -4.2943e-01, -7.7613e-01, -1.3463e+00, -1.6947e+00, -1.6382e+00,\n",
      "           3.8687e-01,  2.1547e+00],\n",
      "         [ 9.1019e-01, -1.4873e-01,  1.6014e+00,  1.3995e-02,  6.8649e-01,\n",
      "          -4.6609e-01, -6.1476e-01, -1.4606e+00, -1.6964e+00, -1.4245e+00,\n",
      "           3.8821e-01,  2.4695e+00],\n",
      "         [ 1.0201e+00, -3.0966e-01,  1.4013e+00,  1.1447e-02,  2.3091e-01,\n",
      "          -4.8021e-01, -4.9354e-01, -1.4684e+00, -1.6752e+00, -1.1515e+00,\n",
      "           3.6571e-01,  2.8064e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.6112,  1.7149, -4.3948,  0.0614]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-5.9634e-01,  1.6153e+00,  1.8461e+00, -1.1703e-01,  1.5781e+00,\n",
      "           5.8687e-01, -1.1237e+00, -3.9868e-01, -7.0449e-01, -2.1012e+00,\n",
      "           1.9538e-01, -7.5867e-01],\n",
      "         [ 1.5361e-01,  5.1322e-01,  1.7468e+00,  8.2632e-02,  2.0158e+00,\n",
      "          -1.2180e-01, -1.1890e+00, -9.4654e-01, -1.5047e+00, -2.0150e+00,\n",
      "           5.3739e-01,  9.1754e-01],\n",
      "         [ 4.1859e-01,  2.7507e-01,  1.8131e+00,  2.2498e-03,  1.6174e+00,\n",
      "          -2.2698e-01, -1.0423e+00, -1.1356e+00, -1.5871e+00, -1.9409e+00,\n",
      "           5.5064e-01,  1.4812e+00],\n",
      "         [ 9.5014e-01, -3.0804e-01,  1.9143e+00, -1.4826e-01,  8.8666e-01,\n",
      "          -1.8743e-01, -1.0859e+00, -1.0961e+00, -1.6832e+00, -1.4982e+00,\n",
      "           4.1413e-01,  2.0918e+00],\n",
      "         [ 7.8672e-01, -2.9418e-02,  1.7032e+00,  4.0243e-02,  1.0964e+00,\n",
      "          -4.2943e-01, -7.7613e-01, -1.3463e+00, -1.6947e+00, -1.6382e+00,\n",
      "           3.8687e-01,  2.1547e+00],\n",
      "         [ 9.1019e-01, -1.4873e-01,  1.6014e+00,  1.3995e-02,  6.8649e-01,\n",
      "          -4.6609e-01, -6.1476e-01, -1.4606e+00, -1.6964e+00, -1.4245e+00,\n",
      "           3.8821e-01,  2.4695e+00],\n",
      "         [ 1.0201e+00, -3.0966e-01,  1.4013e+00,  1.1447e-02,  2.3091e-01,\n",
      "          -4.8021e-01, -4.9354e-01, -1.4684e+00, -1.6752e+00, -1.1515e+00,\n",
      "           3.6571e-01,  2.8064e+00],\n",
      "         [ 1.1100e+00, -4.7984e-01,  1.1571e+00,  2.8058e-02, -1.9557e-01,\n",
      "          -4.9524e-01, -3.9795e-01, -1.3771e+00, -1.6039e+00, -8.8289e-01,\n",
      "           3.0370e-01,  3.0829e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.2812,  1.4429, -4.4632,  0.4574]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-5.9634e-01,  1.6153e+00,  1.8461e+00, -1.1703e-01,  1.5781e+00,\n",
      "           5.8687e-01, -1.1237e+00, -3.9868e-01, -7.0449e-01, -2.1012e+00,\n",
      "           1.9538e-01, -7.5867e-01],\n",
      "         [ 1.5361e-01,  5.1322e-01,  1.7468e+00,  8.2632e-02,  2.0158e+00,\n",
      "          -1.2180e-01, -1.1890e+00, -9.4654e-01, -1.5047e+00, -2.0150e+00,\n",
      "           5.3739e-01,  9.1754e-01],\n",
      "         [ 4.1859e-01,  2.7507e-01,  1.8131e+00,  2.2498e-03,  1.6174e+00,\n",
      "          -2.2698e-01, -1.0423e+00, -1.1356e+00, -1.5871e+00, -1.9409e+00,\n",
      "           5.5064e-01,  1.4812e+00],\n",
      "         [ 9.5014e-01, -3.0804e-01,  1.9143e+00, -1.4826e-01,  8.8666e-01,\n",
      "          -1.8743e-01, -1.0859e+00, -1.0961e+00, -1.6832e+00, -1.4982e+00,\n",
      "           4.1413e-01,  2.0918e+00],\n",
      "         [ 7.8672e-01, -2.9418e-02,  1.7032e+00,  4.0243e-02,  1.0964e+00,\n",
      "          -4.2943e-01, -7.7613e-01, -1.3463e+00, -1.6947e+00, -1.6382e+00,\n",
      "           3.8687e-01,  2.1547e+00],\n",
      "         [ 9.1019e-01, -1.4873e-01,  1.6014e+00,  1.3995e-02,  6.8649e-01,\n",
      "          -4.6609e-01, -6.1476e-01, -1.4606e+00, -1.6964e+00, -1.4245e+00,\n",
      "           3.8821e-01,  2.4695e+00],\n",
      "         [ 1.0201e+00, -3.0966e-01,  1.4013e+00,  1.1447e-02,  2.3091e-01,\n",
      "          -4.8021e-01, -4.9354e-01, -1.4684e+00, -1.6752e+00, -1.1515e+00,\n",
      "           3.6571e-01,  2.8064e+00],\n",
      "         [ 1.1100e+00, -4.7984e-01,  1.1571e+00,  2.8058e-02, -1.9557e-01,\n",
      "          -4.9524e-01, -3.9795e-01, -1.3771e+00, -1.6039e+00, -8.8289e-01,\n",
      "           3.0370e-01,  3.0829e+00],\n",
      "         [ 1.1480e+00, -6.0037e-01,  9.4935e-01,  3.7641e-02, -5.3161e-01,\n",
      "          -5.1014e-01, -3.1719e-01, -1.2556e+00, -1.5157e+00, -6.6215e-01,\n",
      "           2.4044e-01,  3.2564e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 0.9948,  1.2125, -4.4292,  0.7690]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "yv_i tensor([2, 1, 0, 1, 0, 1, 1, 0, 1, 3], device='cuda:0')\n",
      "prediction tensor([2, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "\n",
      "xv_i tensor([2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 3], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2]], device='cuda:0') ys\n",
      "tensor([[ 1.9492,  2.0136, -0.7787, -2.5063]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.4251,  2.3518, -2.5846, -1.6940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 2.2131,  2.2936, -3.4552, -1.2203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.2335,  2.2957, -3.5508, -1.0374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.1177,  2.1232, -3.9537, -0.6977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.9085,  1.8740, -4.2471, -0.3412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035],\n",
      "         [ 1.1288, -0.6601,  1.3922, -0.1988, -0.3689, -0.1136, -0.7826,\n",
      "          -1.0776, -1.6617, -0.6556,  0.2344,  3.0170]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 1.1865,  1.3552, -4.4923,  0.3852]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035],\n",
      "         [ 1.1288, -0.6601,  1.3922, -0.1988, -0.3689, -0.1136, -0.7826,\n",
      "          -1.0776, -1.6617, -0.6556,  0.2344,  3.0170],\n",
      "         [ 1.1614, -0.5539,  1.1018, -0.0831, -0.2899, -0.2808, -0.5148,\n",
      "          -1.2700, -1.6579, -0.7209,  0.2225,  3.1418]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.1497,  1.3716, -4.4711,  0.5277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035],\n",
      "         [ 1.1288, -0.6601,  1.3922, -0.1988, -0.3689, -0.1136, -0.7826,\n",
      "          -1.0776, -1.6617, -0.6556,  0.2344,  3.0170],\n",
      "         [ 1.1614, -0.5539,  1.1018, -0.0831, -0.2899, -0.2808, -0.5148,\n",
      "          -1.2700, -1.6579, -0.7209,  0.2225,  3.1418],\n",
      "         [ 1.1841, -0.6730,  0.8869, -0.0701, -0.6337, -0.3089, -0.4273,\n",
      "          -1.1356, -1.5578, -0.4835,  0.1608,  3.3023]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 0.8511,  1.1259, -4.4046,  0.8478]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "yv_i tensor([2, 1, 1, 1, 0, 0, 1, 1, 1, 3], device='cuda:0')\n",
      "prediction tensor([2, 1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "\n",
      "xv_i tensor([2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 3], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([[[-0.6070,  1.6234,  1.8250, -0.1175,  1.5908,  0.5833, -1.1168,\n",
      "          -0.3921, -0.6869, -2.1044,  0.2005, -0.7778]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2]], device='cuda:0') ys\n",
      "tensor([[ 1.9812,  2.0265, -0.7469, -2.5291]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6070,  1.6234,  1.8250, -0.1175,  1.5908,  0.5833, -1.1168,\n",
      "          -0.3921, -0.6869, -2.1044,  0.2005, -0.7778],\n",
      "         [ 0.1442,  0.5207,  1.7357,  0.0805,  2.0328, -0.1220, -1.1808,\n",
      "          -0.9456, -1.4918, -2.0271,  0.5451,  0.8974]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.3653,  2.4058, -2.6330, -1.6411]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-6.0704e-01,  1.6234e+00,  1.8250e+00, -1.1749e-01,  1.5908e+00,\n",
      "           5.8328e-01, -1.1168e+00, -3.9209e-01, -6.8694e-01, -2.1044e+00,\n",
      "           2.0055e-01, -7.7783e-01],\n",
      "         [ 1.4419e-01,  5.2069e-01,  1.7357e+00,  8.0455e-02,  2.0328e+00,\n",
      "          -1.2204e-01, -1.1808e+00, -9.4557e-01, -1.4918e+00, -2.0271e+00,\n",
      "           5.4510e-01,  8.9738e-01],\n",
      "         [ 4.1321e-01,  2.7984e-01,  1.8045e+00, -9.7541e-04,  1.6324e+00,\n",
      "          -2.2652e-01, -1.0346e+00, -1.1372e+00, -1.5768e+00, -1.9556e+00,\n",
      "           5.5983e-01,  1.4668e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.3416,  2.3251, -3.2999, -1.2967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-6.0704e-01,  1.6234e+00,  1.8250e+00, -1.1749e-01,  1.5908e+00,\n",
      "           5.8328e-01, -1.1168e+00, -3.9209e-01, -6.8694e-01, -2.1044e+00,\n",
      "           2.0055e-01, -7.7783e-01],\n",
      "         [ 1.4419e-01,  5.2069e-01,  1.7357e+00,  8.0455e-02,  2.0328e+00,\n",
      "          -1.2204e-01, -1.1808e+00, -9.4557e-01, -1.4918e+00, -2.0271e+00,\n",
      "           5.4510e-01,  8.9738e-01],\n",
      "         [ 4.1321e-01,  2.7984e-01,  1.8045e+00, -9.7541e-04,  1.6324e+00,\n",
      "          -2.2652e-01, -1.0346e+00, -1.1372e+00, -1.5768e+00, -1.9556e+00,\n",
      "           5.5983e-01,  1.4668e+00],\n",
      "         [ 9.5279e-01, -3.1606e-01,  1.9061e+00, -1.4970e-01,  8.9758e-01,\n",
      "          -1.9291e-01, -1.0787e+00, -1.0993e+00, -1.6770e+00, -1.5072e+00,\n",
      "           4.2395e-01,  2.0906e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 1.9923,  2.1150, -4.0742, -0.6525]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-6.0704e-01,  1.6234e+00,  1.8250e+00, -1.1749e-01,  1.5908e+00,\n",
      "           5.8328e-01, -1.1168e+00, -3.9209e-01, -6.8694e-01, -2.1044e+00,\n",
      "           2.0055e-01, -7.7783e-01],\n",
      "         [ 1.4419e-01,  5.2069e-01,  1.7357e+00,  8.0456e-02,  2.0328e+00,\n",
      "          -1.2204e-01, -1.1808e+00, -9.4557e-01, -1.4918e+00, -2.0271e+00,\n",
      "           5.4510e-01,  8.9738e-01],\n",
      "         [ 4.1321e-01,  2.7984e-01,  1.8045e+00, -9.7540e-04,  1.6324e+00,\n",
      "          -2.2652e-01, -1.0346e+00, -1.1372e+00, -1.5768e+00, -1.9556e+00,\n",
      "           5.5983e-01,  1.4668e+00],\n",
      "         [ 9.5279e-01, -3.1606e-01,  1.9061e+00, -1.4970e-01,  8.9758e-01,\n",
      "          -1.9291e-01, -1.0787e+00, -1.0993e+00, -1.6770e+00, -1.5072e+00,\n",
      "           4.2394e-01,  2.0906e+00],\n",
      "         [ 7.8101e-01, -3.2726e-02,  1.6981e+00,  3.9859e-02,  1.1088e+00,\n",
      "          -4.3134e-01, -7.6294e-01, -1.3534e+00, -1.6890e+00, -1.6492e+00,\n",
      "           3.9688e-01,  2.1477e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.0598,  2.2021, -3.9303, -0.6412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-6.0704e-01,  1.6234e+00,  1.8250e+00, -1.1749e-01,  1.5908e+00,\n",
      "           5.8328e-01, -1.1168e+00, -3.9209e-01, -6.8694e-01, -2.1044e+00,\n",
      "           2.0055e-01, -7.7783e-01],\n",
      "         [ 1.4419e-01,  5.2069e-01,  1.7357e+00,  8.0456e-02,  2.0328e+00,\n",
      "          -1.2204e-01, -1.1808e+00, -9.4557e-01, -1.4918e+00, -2.0271e+00,\n",
      "           5.4510e-01,  8.9738e-01],\n",
      "         [ 4.1321e-01,  2.7984e-01,  1.8045e+00, -9.7540e-04,  1.6324e+00,\n",
      "          -2.2652e-01, -1.0346e+00, -1.1372e+00, -1.5768e+00, -1.9556e+00,\n",
      "           5.5983e-01,  1.4668e+00],\n",
      "         [ 9.5279e-01, -3.1606e-01,  1.9061e+00, -1.4970e-01,  8.9758e-01,\n",
      "          -1.9291e-01, -1.0787e+00, -1.0993e+00, -1.6770e+00, -1.5072e+00,\n",
      "           4.2394e-01,  2.0906e+00],\n",
      "         [ 7.8101e-01, -3.2726e-02,  1.6981e+00,  3.9859e-02,  1.1088e+00,\n",
      "          -4.3134e-01, -7.6294e-01, -1.3534e+00, -1.6890e+00, -1.6492e+00,\n",
      "           3.9688e-01,  2.1477e+00],\n",
      "         [ 9.0782e-01, -1.5274e-01,  1.5971e+00,  1.2994e-02,  6.9517e-01,\n",
      "          -4.6773e-01, -5.9824e-01, -1.4705e+00, -1.6903e+00, -1.4362e+00,\n",
      "           3.9783e-01,  2.4630e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.8986,  1.9839, -4.1978, -0.3281]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-6.0704e-01,  1.6234e+00,  1.8250e+00, -1.1749e-01,  1.5908e+00,\n",
      "           5.8328e-01, -1.1168e+00, -3.9209e-01, -6.8694e-01, -2.1044e+00,\n",
      "           2.0055e-01, -7.7783e-01],\n",
      "         [ 1.4419e-01,  5.2069e-01,  1.7357e+00,  8.0456e-02,  2.0328e+00,\n",
      "          -1.2204e-01, -1.1808e+00, -9.4557e-01, -1.4918e+00, -2.0271e+00,\n",
      "           5.4510e-01,  8.9738e-01],\n",
      "         [ 4.1321e-01,  2.7984e-01,  1.8045e+00, -9.7540e-04,  1.6324e+00,\n",
      "          -2.2652e-01, -1.0346e+00, -1.1372e+00, -1.5768e+00, -1.9556e+00,\n",
      "           5.5983e-01,  1.4668e+00],\n",
      "         [ 9.5279e-01, -3.1606e-01,  1.9061e+00, -1.4970e-01,  8.9758e-01,\n",
      "          -1.9291e-01, -1.0787e+00, -1.0993e+00, -1.6770e+00, -1.5072e+00,\n",
      "           4.2394e-01,  2.0906e+00],\n",
      "         [ 7.8101e-01, -3.2726e-02,  1.6981e+00,  3.9859e-02,  1.1088e+00,\n",
      "          -4.3134e-01, -7.6294e-01, -1.3534e+00, -1.6890e+00, -1.6492e+00,\n",
      "           3.9688e-01,  2.1477e+00],\n",
      "         [ 9.0782e-01, -1.5274e-01,  1.5971e+00,  1.2994e-02,  6.9517e-01,\n",
      "          -4.6773e-01, -5.9824e-01, -1.4705e+00, -1.6903e+00, -1.4362e+00,\n",
      "           3.9783e-01,  2.4630e+00],\n",
      "         [ 1.0216e+00, -3.1296e-01,  1.3935e+00,  9.3145e-03,  2.3609e-01,\n",
      "          -4.8057e-01, -4.7731e-01, -1.4794e+00, -1.6705e+00, -1.1587e+00,\n",
      "           3.7227e-01,  2.8040e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.6221,  1.7098, -4.3926,  0.0619]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-6.0704e-01,  1.6234e+00,  1.8250e+00, -1.1749e-01,  1.5908e+00,\n",
      "           5.8328e-01, -1.1168e+00, -3.9209e-01, -6.8694e-01, -2.1044e+00,\n",
      "           2.0055e-01, -7.7783e-01],\n",
      "         [ 1.4419e-01,  5.2069e-01,  1.7357e+00,  8.0456e-02,  2.0328e+00,\n",
      "          -1.2204e-01, -1.1808e+00, -9.4557e-01, -1.4918e+00, -2.0271e+00,\n",
      "           5.4510e-01,  8.9738e-01],\n",
      "         [ 4.1321e-01,  2.7984e-01,  1.8045e+00, -9.7540e-04,  1.6324e+00,\n",
      "          -2.2652e-01, -1.0346e+00, -1.1372e+00, -1.5768e+00, -1.9556e+00,\n",
      "           5.5983e-01,  1.4668e+00],\n",
      "         [ 9.5279e-01, -3.1606e-01,  1.9061e+00, -1.4970e-01,  8.9758e-01,\n",
      "          -1.9291e-01, -1.0787e+00, -1.0993e+00, -1.6770e+00, -1.5072e+00,\n",
      "           4.2394e-01,  2.0906e+00],\n",
      "         [ 7.8101e-01, -3.2726e-02,  1.6981e+00,  3.9859e-02,  1.1088e+00,\n",
      "          -4.3134e-01, -7.6294e-01, -1.3534e+00, -1.6890e+00, -1.6492e+00,\n",
      "           3.9688e-01,  2.1477e+00],\n",
      "         [ 9.0782e-01, -1.5274e-01,  1.5971e+00,  1.2994e-02,  6.9517e-01,\n",
      "          -4.6773e-01, -5.9824e-01, -1.4705e+00, -1.6903e+00, -1.4362e+00,\n",
      "           3.9783e-01,  2.4630e+00],\n",
      "         [ 1.0216e+00, -3.1296e-01,  1.3935e+00,  9.3145e-03,  2.3609e-01,\n",
      "          -4.8057e-01, -4.7731e-01, -1.4794e+00, -1.6705e+00, -1.1587e+00,\n",
      "           3.7227e-01,  2.8040e+00],\n",
      "         [ 1.1123e+00, -4.8484e-01,  1.1475e+00,  2.6358e-02, -1.9454e-01,\n",
      "          -4.9542e-01, -3.8158e-01, -1.3865e+00, -1.5990e+00, -8.8747e-01,\n",
      "           3.0932e-01,  3.0829e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.2887,  1.4356, -4.4616,  0.4615]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-6.0704e-01,  1.6234e+00,  1.8250e+00, -1.1749e-01,  1.5908e+00,\n",
      "           5.8328e-01, -1.1168e+00, -3.9209e-01, -6.8694e-01, -2.1044e+00,\n",
      "           2.0055e-01, -7.7783e-01],\n",
      "         [ 1.4419e-01,  5.2069e-01,  1.7357e+00,  8.0456e-02,  2.0328e+00,\n",
      "          -1.2204e-01, -1.1808e+00, -9.4557e-01, -1.4918e+00, -2.0271e+00,\n",
      "           5.4510e-01,  8.9738e-01],\n",
      "         [ 4.1321e-01,  2.7984e-01,  1.8045e+00, -9.7540e-04,  1.6324e+00,\n",
      "          -2.2652e-01, -1.0346e+00, -1.1372e+00, -1.5768e+00, -1.9556e+00,\n",
      "           5.5983e-01,  1.4668e+00],\n",
      "         [ 9.5279e-01, -3.1606e-01,  1.9061e+00, -1.4970e-01,  8.9758e-01,\n",
      "          -1.9291e-01, -1.0787e+00, -1.0993e+00, -1.6770e+00, -1.5072e+00,\n",
      "           4.2394e-01,  2.0906e+00],\n",
      "         [ 7.8101e-01, -3.2726e-02,  1.6981e+00,  3.9859e-02,  1.1088e+00,\n",
      "          -4.3134e-01, -7.6294e-01, -1.3534e+00, -1.6890e+00, -1.6492e+00,\n",
      "           3.9688e-01,  2.1477e+00],\n",
      "         [ 9.0782e-01, -1.5274e-01,  1.5971e+00,  1.2994e-02,  6.9517e-01,\n",
      "          -4.6773e-01, -5.9824e-01, -1.4705e+00, -1.6903e+00, -1.4362e+00,\n",
      "           3.9783e-01,  2.4630e+00],\n",
      "         [ 1.0216e+00, -3.1296e-01,  1.3935e+00,  9.3145e-03,  2.3609e-01,\n",
      "          -4.8057e-01, -4.7731e-01, -1.4794e+00, -1.6705e+00, -1.1587e+00,\n",
      "           3.7227e-01,  2.8040e+00],\n",
      "         [ 1.1123e+00, -4.8484e-01,  1.1475e+00,  2.6358e-02, -1.9454e-01,\n",
      "          -4.9542e-01, -3.8158e-01, -1.3865e+00, -1.5990e+00, -8.8747e-01,\n",
      "           3.0932e-01,  3.0829e+00],\n",
      "         [ 1.1500e+00, -6.0611e-01,  9.3864e-01,  3.5227e-02, -5.3297e-01,\n",
      "          -5.1070e-01, -3.0090e-01, -1.2630e+00, -1.5097e+00, -6.6450e-01,\n",
      "           2.4515e-01,  3.2576e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 1, 0, 1, 1, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 0.9996,  1.2035, -4.4264,  0.7754]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "yv_i tensor([2, 0, 0, 0, 0, 1, 1, 1, 0, 3], device='cuda:0')\n",
      "prediction tensor([2, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "\n",
      "xv_i tensor([2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 3], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2]], device='cuda:0') ys\n",
      "tensor([[ 1.9492,  2.0136, -0.7787, -2.5063]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.4251,  2.3518, -2.5846, -1.6940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 2.2131,  2.2936, -3.4552, -1.2203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.2335,  2.2957, -3.5508, -1.0374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 2.1177,  2.1232, -3.9537, -0.6977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.9085,  1.8740, -4.2471, -0.3412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035],\n",
      "         [ 1.1288, -0.6601,  1.3922, -0.1988, -0.3689, -0.1136, -0.7826,\n",
      "          -1.0776, -1.6617, -0.6556,  0.2344,  3.0170]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1, 0]], device='cuda:0') ys\n",
      "tensor([[ 1.1865,  1.3552, -4.4923,  0.3852]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035],\n",
      "         [ 1.1288, -0.6601,  1.3922, -0.1988, -0.3689, -0.1136, -0.7826,\n",
      "          -1.0776, -1.6617, -0.6556,  0.2344,  3.0170],\n",
      "         [ 1.1614, -0.5539,  1.1018, -0.0831, -0.2899, -0.2808, -0.5148,\n",
      "          -1.2700, -1.6579, -0.7209,  0.2225,  3.1418]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1, 0, 1]], device='cuda:0') ys\n",
      "tensor([[ 1.1497,  1.3716, -4.4711,  0.5277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "tensor([[[-0.6280,  1.6423,  1.8768, -0.2662,  1.5226,  0.6821, -1.1435,\n",
      "          -0.3153, -0.7511, -2.0310,  0.1452, -0.6937],\n",
      "         [ 0.0872,  0.5035,  1.7554, -0.0619,  2.0380,  0.0854, -1.1793,\n",
      "          -0.8998, -1.5070, -2.0250,  0.5180,  0.8824],\n",
      "         [ 0.5726,  0.0512,  2.0009, -0.1943,  1.4484,  0.0675, -1.2951,\n",
      "          -0.9454, -1.7281, -1.6693,  0.4393,  1.4868],\n",
      "         [ 0.5727,  0.0968,  1.7434, -0.0642,  1.5184, -0.1479, -1.0103,\n",
      "          -1.1843, -1.7148, -1.7651,  0.4416,  1.7640],\n",
      "         [ 0.7556, -0.0744,  1.7128, -0.0919,  1.0895, -0.1839, -0.8164,\n",
      "          -1.3479, -1.7584, -1.5864,  0.4151,  2.1462],\n",
      "         [ 0.8993, -0.2161,  1.5968, -0.1160,  0.6255, -0.2078, -0.6724,\n",
      "          -1.4753, -1.7642, -1.3056,  0.3982,  2.5035],\n",
      "         [ 1.1288, -0.6601,  1.3922, -0.1988, -0.3689, -0.1136, -0.7826,\n",
      "          -1.0776, -1.6617, -0.6556,  0.2344,  3.0170],\n",
      "         [ 1.1614, -0.5539,  1.1018, -0.0831, -0.2899, -0.2808, -0.5148,\n",
      "          -1.2700, -1.6579, -0.7209,  0.2225,  3.1418],\n",
      "         [ 1.1841, -0.6730,  0.8869, -0.0701, -0.6337, -0.3089, -0.4273,\n",
      "          -1.1356, -1.5578, -0.4835,  0.1608,  3.3023]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>) out\n",
      "tensor([[2, 1, 0, 1, 1, 1, 0, 1, 1]], device='cuda:0') ys\n",
      "tensor([[ 0.8511,  1.1259, -4.4046,  0.8478]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) prob\n",
      "\n",
      "yv_i tensor([2, 1, 1, 1, 0, 0, 1, 1, 1, 3], device='cuda:0')\n",
      "prediction tensor([2, 1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len):\n",
    "    \"\"\"Standard autoregressive decoder output scheme.\n",
    "\n",
    "    Current issue: my train batching didn't have time-sliced data, so I think the \n",
    "    model has no idea what to do with a length-1 <SOS> sequence as input.\n",
    "    \"\"\"\n",
    "    src = src.to(DEVICE)\n",
    "    # src_mask = src_mask.to(DEVICE)\n",
    "    src_mask = None  # FIXME\n",
    "    \n",
    "    # For a single example evaluation, we need to add a dummy batch dimension (1, *) with unsqueeze(0)\n",
    "    memory = model.encode(src.unsqueeze(0), src_mask)\n",
    "    # The [1, 1] shape starts us off with a dummy batch dimension \n",
    "    ys = torch.ones(1, 1).fill_(SOS_TOKEN).type(torch.long).to(DEVICE)\n",
    "\n",
    "    # FIXME: should I enforce the length? Or should I enforce the length+1, \n",
    "    # and then checksum for an EOS? Or should I allow variable length :(\n",
    "    for i in range(max_len - 1): # -1 since we start with SOS\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (ucan_transformer.generate_square_subsequent_mask(ys.size(1), device=DEVICE).type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(tgt=ys, memory=memory, tgt_mask=tgt_mask) # (1, tgt_seq_len, emb_dim)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        print(out, \"out\")\n",
    "        print(ys, \"ys\")\n",
    "        print(prob, \"prob\")\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        print()\n",
    "    return ys\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "# inp\n",
    "def translate(model: torch.nn.Module, src):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        src: tensor. single input bitstring of length 2n + 2. Shape (2n + 2,) \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    seq_len = src.shape[0] - 2\n",
    "    out_len = seq_len // 2 + 2 # 2:1 UCAN conversion, plus EOS/SOS\n",
    "    # src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    src_mask = None\n",
    "    tgt_tokens = greedy_decode(model, src, src_mask, max_len=out_len).flatten()\n",
    "\n",
    "    return tgt_tokens\n",
    "\n",
    "\n",
    "xv, yv = get_batch('val')\n",
    "\n",
    "for xvi, yvi in zip(xv, yv):\n",
    "    print(\"xv_i\", xvi)\n",
    "    pred = translate(model, xvi)\n",
    "    print(\"yv_i\", yvi)\n",
    "    print(\"prediction\", pred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to use DataLoader, Dataset, etc. for batching\n",
    "\n",
    "def train_step(model, optimizer):\n",
    "    losses = 0\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        # These aren't technically epochs i guess.\n",
    "        xb, yb = get_batch('train')\n",
    "\n",
    "        logits = model(xb, yb, None, None) # No masks for now\n",
    "        optimizer.zero_grad(set_to_none=True) #?\n",
    "\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), yb.reshape(-1))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        losses += loss.item() / BATCH_SIZE # check this\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 10]) embedding\n",
      "torch.Size([4, 16, 10]) positional\n",
      "torch.Size([4, 8, 2]) model forward\n"
     ]
    }
   ],
   "source": [
    "emb_size = 10\n",
    "x, y = get_batch('train')\n",
    "embedding = TokenEmbedding(2, emb_size)\n",
    "xx = embedding.forward(x)\n",
    "print(xx.shape, \"embedding\")\n",
    "positional = PositionalEncoding(emb_size, 0.1)\n",
    "xxx = positional.forward(xx)\n",
    "print(xxx.shape, \"positional\")\n",
    "\n",
    "xxxx = model.forward(x, y, None, None)\n",
    "print(xxxx.shape, \"model forward\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "Re-adapt this for prediction/evaluation, and probably incorporate as a function into the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Scratchwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "# inp\n",
    "def translate(model: torch.nn.Module, src):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        single\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "SRC_LANGUAGE = 'fuck'\n",
    "TGT_LANGUAGE = 'this'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "    \n",
    "\n",
    "val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi30k, Multi30k\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fixme\u001b[39;00m\n\u001b[0;32m      5\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "\n",
    "# Fixme\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
