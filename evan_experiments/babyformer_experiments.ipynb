{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were experiments to find examples of computing XOR with a (limited) ENCODER-DECODER model. After doing some theory, here are thoughts so far:\n",
    " - Single layer encoder-decoder: With _unbiased_ encoder FFNN, no decoder self-attention, no Layer-Norm, and no decoder FFNN, this is IMPOSSIBLE. Thoughts: decoder FFNN, decoder self-attention will probably not affect this result.\n",
    " - Next thing is to check is with bias. I bet that helps a lot\n",
    " - A two layer encoder can do this arbitrarily well (https://arxiv.org/pdf/2202.12172)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "XOR_INPUTS = [np.array([[1, 0], [1, 0]]), np.array([[0, 1], [1, 0]]), np.array([[1, 0], [0, 1]]), np.array([[0, 1], [0, 1]]), ]\n",
    "INPUTS = [(0, 0), (1, 0), (0, 1), (1, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPERIMENT 1: Single layer, encoder-decoder, but no FFNN at the end of encoder.\n",
    "Output of encoder is\n",
    "$$\n",
    "H = \\sigma(X W_Q W_K^T X^T) X W_V\n",
    "$$\n",
    "\n",
    "Output of decoder times linear layer is\n",
    "$$\n",
    "D = \\sigma(q^T H) H W\n",
    "$$\n",
    "Where $W = W_V^{dec} W'$ absorbs the decoder values matrix and $q^T = v_{SOS} W_Q^{dec} (W_K^{dec})^T$ absorbs several weight matrices. \n",
    "\n",
    "**Finding**: Without the FFNN at the end of the encoder, I'm actually, very suspicious that this might just be a mostly-linear function, i.e. the input appears right here:\n",
    "$$\n",
    "D = \\sigma(q^T \\sigma(X W_Q W_K^T X^T) X W_V) \\sigma(X W_Q W_K^T X^T) \\textcolor{red}{X} W_V W \n",
    "$$\n",
    "Actually, I think what matters here the most is the BIAS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    return np.exp(X) / np.sum(np.exp(X), axis=0)\n",
    "\n",
    "\n",
    "# Compute Q, K, V for encoder self-attention\n",
    "def get_QKV(X, Wq, Wk, Wv):\n",
    "\n",
    "    Q = X @ Wq\n",
    "    K = X @ Wk\n",
    "    V = X @ Wv\n",
    "    return Q, K, V\n",
    "\n",
    "# Compute output of encoder\n",
    "def encoder(X, Wq, Wk, Wv):\n",
    "    Q, K, V = get_QKV(X, Wq, Wk, Wv)\n",
    "    Z = softmax(Q @ K.T) @ V\n",
    "    return Z\n",
    "\n",
    "def rowwise_FFNN(X, W1, W2):\n",
    "    \"\"\"With ReLU activation function.\"\"\"\n",
    "    return np.maximum(0, X @ W1) @ W2\n",
    "\n",
    "# Compute output of decoder with cross attention\n",
    "def sigma_qkt(memory, v):   \n",
    "    return softmax(v @ memory)\n",
    "\n",
    "def decoder_linear(memory, v, W):\n",
    "    return sigma_qkt(memory, v) @ memory @ W\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair (0, 0) S:\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "pair (1, 0) S:\n",
      "[[0.88079708 0.11920292]\n",
      " [0.11920292 0.88079708]]\n",
      "pair (0, 1) S:\n",
      "[[0.88079708 0.11920292]\n",
      " [0.11920292 0.88079708]]\n",
      "pair (1, 1) S:\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "Wq = np.array([[1, 1], [1, -1]])\n",
    "Wk = np.array([[1, 1], [1, -1]])\n",
    "for pair, X in zip(INPUTS, XOR_INPUTS):\n",
    "    \n",
    "    S = softmax(X @ Wq @ Wk.T @ X.T)\n",
    "    print(f\"pair {pair} S:\")\n",
    "    print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) encoder\n",
      "[[1.  0.5]\n",
      " [1.  0.5]]\n",
      "[[1.  0.5]\n",
      " [1.  0.5]]\n",
      "sigma_qT_H [0.62657407 0.37342593]\n",
      "     decoder_prelinear [1.  0.5]\n",
      "output: (0, 0) -> [0.62245933 0.37754067]\n",
      "\n",
      "(1, 0) encoder\n",
      "[[ 0.55960146 -0.82119562]\n",
      " [ 0.94039854  0.32119562]]\n",
      "[[0.55960146 0.        ]\n",
      " [0.94039854 0.32119562]]\n",
      "sigma_qT_H [0.64558294 0.35441706]\n",
      "     decoder_prelinear [0.69456244 0.1138372 ]\n",
      "output: (1, 0) -> [0.64123427 0.35876573]\n",
      "\n",
      "(0, 1) encoder\n",
      "[[ 0.94039854  0.32119562]\n",
      " [ 0.55960146 -0.82119562]]\n",
      "[[0.94039854 0.32119562]\n",
      " [0.55960146 0.        ]]\n",
      "sigma_qT_H [0.65033107 0.34966893]\n",
      "     decoder_prelinear [0.80724563 0.20888349]\n",
      "output: (0, 1) -> [0.6452815 0.3547185]\n",
      "\n",
      "(1, 1) encoder\n",
      "[[ 0.5 -1. ]\n",
      " [ 0.5 -1. ]]\n",
      "[[0.5 0. ]\n",
      " [0.5 0. ]]\n",
      "sigma_qT_H [0.62657407 0.37342593]\n",
      "     decoder_prelinear [0.5 0. ]\n",
      "output: (1, 1) -> [0.62245933 0.37754067]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify query vector for the SOS token\n",
    "# This abosrbs the Wq and Wk matrices for decoder\n",
    "\n",
    "\n",
    "# Specify encoder Wq, Wk, Wv for self-attention\n",
    "Wq = np.array([[1, 1], [1, -1]])\n",
    "Wk = np.array([[1, 1], [1, -1]])\n",
    "Wv = np.array(\n",
    "    [[1, 1/2],\n",
    "     [1/2, -1]]\n",
    "\n",
    ")\n",
    "# Wq = np.random.rand(2, 2)\n",
    "# Wk = np.random.rand(2, 2)\n",
    "# Wv = np.random.rand(2, 2)\n",
    "\n",
    "W1 = np.array([[1, 0], [0, 1]])\n",
    "W2 = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "# DECODER\n",
    "# vqk_vec = np.array([-1, .2])\n",
    "vqk_vec = np.random.rand(2)\n",
    "W = np.array(\n",
    "    [[1, 0],\n",
    "     [0, 1]]\n",
    ")\n",
    "\n",
    "for pair, X in zip(INPUTS, XOR_INPUTS):\n",
    "    print(f\"{pair} encoder\")\n",
    "    enc_out = encoder(X, Wq, Wk, Wv)\n",
    "    print(enc_out)\n",
    "    memory = rowwise_FFNN(enc_out, W1, W2)\n",
    "    print(memory)\n",
    "\n",
    "    sigma_q_Kt = sigma_qkt(memory, vqk_vec)\n",
    "    print(\"sigma_qT_H\", sigma_q_Kt)\n",
    "\n",
    "    decoder_prelinear = sigma_qkt(memory, vqk_vec) @ memory\n",
    "    print(\"     decoder_prelinear\", decoder_prelinear)\n",
    "\n",
    "    decoder = decoder_linear(memory, vqk_vec, W)\n",
    "    # print(\"decoder_linear\", decoder)  \n",
    "    print(f\"output: {pair} ->\", softmax(decoder))\n",
    "    print()\n",
    "\n",
    "# print(Wq, Wk, Wv, vqk_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2:\n",
    "\n",
    "Single layer standard encoder-decoder, FFNN after first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]]\n",
      "[[2 0]\n",
      " [2 0]]\n",
      "[[2 0]\n",
      " [2 0]]\n",
      "[[ 1 -1]\n",
      " [ 1 -1]]\n",
      "\n",
      "[[0 1]\n",
      " [1 0]]\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "[[0 0]\n",
      " [0 0]]\n",
      "\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "[[0 0]\n",
      " [0 0]]\n",
      "\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "[[0 2]\n",
      " [0 2]]\n",
      "[[0 2]\n",
      " [0 2]]\n",
      "[[-1  1]\n",
      " [-1  1]]\n",
      "\n",
      "50.0 0.0\n",
      "-50.0 0.0\n",
      "-50.0 0.0\n",
      "50.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.05500000000000001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = np.array([1, 1]) / 2\n",
    "Sigma = np.array([[1, 1], [1, 1]])\n",
    "\n",
    "LAMBDA = 100\n",
    "\n",
    "W_1 = np.array([\n",
    "    [1, 0], \n",
    "    [0, 1]])\n",
    "bias_1 = np.array([-1, -1])\n",
    "B_1 = np.array([bias_1, bias_1])\n",
    "\n",
    "W_2 = np.array([\n",
    "    [LAMBDA, 0], \n",
    "    [LAMBDA, 0]]\n",
    ")\n",
    "bias_2 = np.array([-LAMBDA/2, 0])\n",
    "B_2 = np.array([bias_2, bias_2])\n",
    "\n",
    "\n",
    "vecs = []\n",
    "for pair, X in zip(INPUTS, XOR_INPUTS):\n",
    "    print(X)\n",
    "    print(Sigma @ X)\n",
    "    print(Sigma @ X @ W_1)\n",
    "    print(Sigma @ X @ W_1 + B_1)\n",
    "    print()\n",
    "    attn_output = Sigma @ X\n",
    "    layer_1 = ReLU(attn_output @ W_1 + B_1)\n",
    "    layer_2 = layer_1 @ W_2 + B_2\n",
    "    z = v.T @ layer_2\n",
    "    vecs.append(z)\n",
    "    # print(z)\n",
    "\n",
    "\n",
    "    # # compute alpha, beta\n",
    "    # xsos = np.array([1, 1])\n",
    "    # UQ = np.ones((2, 2))\n",
    "    # UK = np.zeros((2, 2))\n",
    "    # print(\"---\")\n",
    "    # print(xsos @ UQ @ UK.T @ layer_2.T)\n",
    "\n",
    "    # print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for (i, j) in vecs:\n",
    "    print(i, j)\n",
    "    ax.scatter(i, j)\n",
    "    ax.text(i, j, f\"({i}, {j})\")\n",
    "ax.set_xlim(0, ax.get_xlim()[1])\n",
    "ax.set_ylim(0, ax.get_ylim()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.508508920669556\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "x = 0\n",
    "for i in range(int(1e8)):\n",
    "    x += 1\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.arange(5)\n",
    "arr[(4, 3),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
