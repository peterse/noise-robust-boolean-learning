{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "with open('OPENAI_API_KEY', 'r') as f:\n",
    "    OPENAI_API_KEY = f.read().strip()\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import deterministic.py using local file path\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../sequence_generators')\n",
    "import deterministic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_sequence_sets(length, n_train, n_data, p_bitflip=0.0):\n",
    "    sequence_sets = []\n",
    "    for i in range(n_data):\n",
    "        gen = deterministic.SequenceGen(lookback=4, seed=228+i, number_of_generating_methods=1)\n",
    "        data, generating_func = gen.deterministically_generate_sequences(length=length, num_seq=1, save=False)\n",
    "        train_data = data[0][:n_train]\n",
    "        if p_bitflip > 0:\n",
    "            mask = np.random.choice([0, 1], size=(len(train_data),), p=[1-p_bitflip, p_bitflip]).astype(np.uint8)\n",
    "            train_data = np.array(train_data, dtype=np.uint) ^ mask\n",
    "        training_string = \" \".join(train_data.astype(str))\n",
    "        test_string = \" \".join(data[0][n_train:])\n",
    "        sequence_sets.append((training_string, test_string, generating_func[0]))\n",
    "\n",
    "    return sequence_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_completions(model, input_str, steps, num_samples, noisy=False, logprobs=True, top_logprobs=5, temp=None, logit_bias=None, **kwargs):\n",
    "    ''' Sample completions from GPT-3\n",
    "    Args:\n",
    "        input_str: input sequence as a string\n",
    "        steps: number of steps to predict\n",
    "        num_samples: number of samples to return\n",
    "        temp: temperature for sampling\n",
    "        prompt: additional prompt before the input string\n",
    "        model: name of GPT-3 model to use\n",
    "    Returns:\n",
    "        list of completion strings\n",
    "    \n",
    "    https://github.com/ngruver/llmtime/blob/main/models/promptcast.py\n",
    "    '''\n",
    "    trick_token_count = 1000 # this is a trick to get the model to attempt to predict a large number of tokens, which we truncate with the api\n",
    "    chatgpt_sys_message = f\"\"\"You are a helpful assistant that predicts the next bit. The user will provide a sequence containing ONLY 0 or 1, \n",
    "                             and you will predict the next {trick_token_count} digits that come next. The sequence is represented by only digits 0 or 1 separated by spaces, NO COMMAS.\n",
    "                             The data may be noisy, in which case you should predict the most likely sequence.\"\"\"\n",
    "    \n",
    "    extra_input = \"\"\"Please continue the following sequence with only digits 0 or 1 separated by only spaces. Do not produce any additional text. Do not include commas. \n",
    "                     Do not say anything like 'the next terms in the sequence are', just return the numbers. \"\"\"\n",
    "    noisy_prompt = \"\"\"This data has been generated with some bitflip noise. Predict the most likely sequence WITHOUT NOISE. \"\"\"\n",
    "    if noisy:\n",
    "        extra_input = extra_input + noisy_prompt\n",
    "    extra_input = extra_input + \"Sequence:\\n\"\n",
    "\n",
    "    if model in ['gpt-3.5-turbo','gpt-4']:\n",
    "        chatgpt_sys_message = chatgpt_sys_message\n",
    "        extra_input = extra_input\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                    {\"role\": \"system\", \"content\": chatgpt_sys_message},\n",
    "                    {\"role\": \"user\", \"content\": extra_input+input_str}\n",
    "                ],\n",
    "            max_tokens=int(steps), \n",
    "            temperature=temp,\n",
    "            logit_bias=logit_bias,\n",
    "            n=num_samples,\n",
    "            logprobs=logprobs,\n",
    "            top_logprobs=top_logprobs,\n",
    "            **kwargs\n",
    "        )\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_shifted_acc(preds, truth, bounds=(-4, 4)):\n",
    "    \"\"\"Since GPT starts in the wrong place sometimes, we will be generous and look for the best alignment between its predicted string and the test string.\n",
    "    if we have to move by m places, we will discard m of the string during evaluation.\n",
    "    \"\"\"\n",
    "    best_acc = 0\n",
    "    best_shift = 0\n",
    "    preds = np.array(preds)\n",
    "    truth = np.array(truth)\n",
    "    assert len(preds) == len(truth)\n",
    "    for shift in range(bounds[0], bounds[1]):\n",
    "        # minus sign means we shift \n",
    "        if shift < 0:\n",
    "            x = preds[abs(shift):] # shifted preds\n",
    "            y = truth[0:len(x)] # truncated truth\n",
    "        elif shift > 0:\n",
    "            x = truth[shift:] # shifted truth\n",
    "            y = preds[0:len(x)] # truncated preds\n",
    "        else:\n",
    "            x = preds\n",
    "            y = truth\n",
    "\n",
    "        acc = 1 - np.mean(abs(x - y))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_shift = shift\n",
    "    return best_acc, best_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9285714285714286, -2)\n"
     ]
    }
   ],
   "source": [
    "preds = [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
    "truth = [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
    "print(best_shifted_acc(preds, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1\n",
    "\n",
    "Each digit gets its own token (with a space getting another token between each). We will use deterministic data only, and ask GPT to learn to extend a single sequence that we generate.\n",
    "\n",
    " - no noise\n",
    " - single input, space-separated bits\n",
    " - 20 trials, for 20 different generating functions\n",
    " \n",
    " **Succeeded** - the model had no problem doing a 3-lookback sequence extension. One issue is that these data are very repetitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a single-generating-method dataset\n",
    "\n",
    "# For the first attempt, we will have one really long sequence, \n",
    "# and gpt will try to predict the final bit, then we will average\n",
    "# its performance over some large number of evaluations\n",
    "# TODO: hyperparameter tuning with temperature, other gpt-3 parameters from [1]\n",
    "\n",
    "N_BITS=100\n",
    "n_train = 80\n",
    "n_test = N_BITS - n_train\n",
    "n_data=20\n",
    "\n",
    "\n",
    "sequence_sets = make_sequence_sets(N_BITS, n_train, n_data, p_bitflip=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs = 4\n",
    "model = 'gpt-3.5-turbo'\n",
    "steps = n_test*2 - 1\n",
    "\n",
    "completions = []\n",
    "for training_string, test_string, generating_func in sequence_sets:\n",
    "    completion = sample_completions(model, training_string, steps, 1, logprobs=True, top_logprobs=5, temp=1, logit_bias=None)\n",
    "    completions.append( completion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0, Shift: -1\n",
      "Predicted: [0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0]\n",
      "Truth:     [1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: -1\n",
      "Predicted: [1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0]\n",
      "Truth:     [1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: 0\n",
      "Predicted: [1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1]\n",
      "Truth:     [1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1]\n",
      "\n",
      "Accuracy: 0.95, Shift: 0\n",
      "Predicted: [1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1]\n",
      "Truth:     [0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: -4\n",
      "Predicted: [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Truth:     [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: -4\n",
      "Predicted: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Truth:     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: -1\n",
      "Predicted: [1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0]\n",
      "Truth:     [0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: -2\n",
      "Predicted: [1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "Truth:     [0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: 0\n",
      "Predicted: [1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0]\n",
      "Truth:     [1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: -1\n",
      "Predicted: [0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      "Truth:     [0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: 0\n",
      "Predicted: [1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0]\n",
      "Truth:     [1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: -1\n",
      "Predicted: [0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      "Truth:     [0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: -3\n",
      "Predicted: [1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0]\n",
      "Truth:     [0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: -4\n",
      "Predicted: [1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Truth:     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: -3\n",
      "Predicted: [1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "Truth:     [0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: -4\n",
      "Predicted: [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Truth:     [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: 0\n",
      "Predicted: [0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1]\n",
      "Truth:     [0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: -1\n",
      "Predicted: [0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      "Truth:     [0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\n",
      "Accuracy: 1.0, Shift: 0\n",
      "Predicted: [1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1]\n",
      "Truth:     [1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1]\n",
      "\n",
      "Accuracy: 1.0, Shift: -3\n",
      "Predicted: [0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0]\n",
      "Truth:     [1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_data):\n",
    "    completion = completions[i]\n",
    "    preds = np.array([int(x) for x in completion.choices[0].message.content.split()])\n",
    "    truth = np.array([int(x) for x in sequence_sets[i][1].split()])\n",
    "    acc, shift = best_shifted_acc(preds, truth)\n",
    "    print(f\"Accuracy: {acc}, Shift: {shift}\")\n",
    "    print(f\"Predicted: {preds}\")\n",
    "    print(f\"Truth:     {truth}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Add bitflip noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bits = 500 # need more because of bitflip chance...\n",
    "n_train = 400\n",
    "n_test = n_bits - n_train\n",
    "n_data = 20\n",
    "p_bitflip = 0.05\n",
    "noisy_sequence_sets = make_sequence_sets(n_bits, n_train, n_data, p_bitflip=p_bitflip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs = 4\n",
    "model = 'gpt-3.5-turbo'\n",
    "steps = n_test*2 - 1\n",
    "\n",
    "noisy_completions = []\n",
    "for training_string, test_string, generating_func in noisy_sequence_sets:\n",
    "    completion = sample_completions(model, training_string, steps, 1, logprobs=True, top_logprobs=5, temp=1, logit_bias=None, noisy=True)\n",
    "    noisy_completions.append( completion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7604166666666666, Shift: -4\n",
      "Predicted: 1000111001110011100111001110011100111001110011111110011100111001100011000110001110111110111001110011\n",
      "Truth:     1100111001110011100111001110011100111001110011100111001110011100111001110011100111001110011100111001\n",
      "\n",
      "Accuracy: 1.0, Shift: -1\n",
      "Predicted: 1100011000110001100011000110001100011000110001100011000110001100011000110001100011000110001100011000\n",
      "Truth:     1000110001100011000110001100011000110001100011000110001100011000110001100011000110001100011000110001\n",
      "\n",
      "Accuracy: 0.9299999999999999, Shift: 0\n",
      "Predicted: 1110011101111011010111101111011111011001111011110111101111011110111101111011110110101111111110111101\n",
      "Truth:     1110111101111011110111101111011110111101111011110111101111011110111101111011110111101111011110111101\n",
      "\n",
      "Accuracy: 0.9696969696969697, Shift: -1\n",
      "Predicted: 0101001010100101001010010100101001010010100101001010010100101001010010100101001010010100101001010010\n",
      "Truth:     0010100101001010010100101001010010100101001010010100101001010010100101001010010100101001010010100101\n",
      "\n",
      "Accuracy: 0.96875, Shift: -4\n",
      "Predicted: 1000111111011111111111111111111111111111111011111110111111111111111111111111111111111111111111111111\n",
      "Truth:     1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "\n",
      "Accuracy: 0.9583333333333334, Shift: -4\n",
      "Predicted: 0001000000000000000000100000010000010000000000000000000000100000000000000000000000000000000000000000\n",
      "Truth:     0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "\n",
      "Accuracy: 0.92, Shift: 0\n",
      "Predicted: 0100101001010010101101001010011100101000011010110101001010010100101001010010100101001010011100001101\n",
      "Truth:     0100101001010010100101001010010100101001010010100101001010010100101001010010100101001010010100101001\n",
      "\n",
      "Accuracy: 1.0, Shift: -2\n",
      "Predicted: 1000010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010000\n",
      "Truth:     0001000010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010\n",
      "\n",
      "Accuracy: 1.0, Shift: 0\n",
      "Predicted: 1110011100111001110011100111001110011100111001110011100111001110011100111001110011100111001110011100\n",
      "Truth:     1110011100111001110011100111001110011100111001110011100111001110011100111001110011100111001110011100\n",
      "\n",
      "Accuracy: 1.0, Shift: -2\n",
      "Predicted: 1000010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010000\n",
      "Truth:     0001000010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010\n",
      "\n",
      "Accuracy: 1.0, Shift: 0\n",
      "Predicted: 1111011110111101111011110111101111011110111101111011110111101111011110111101111011110111101111011110\n",
      "Truth:     1111011110111101111011110111101111011110111101111011110111101111011110111101111011110111101111011110\n",
      "\n",
      "Accuracy: 0.96, Shift: 0\n",
      "Predicted: 1011000010000100001000010000100001000010000100101000010000100101000010000100001000010000100001000010\n",
      "Truth:     0001000010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010\n",
      "\n",
      "Accuracy: 0.9795918367346939, Shift: 2\n",
      "Predicted: 1100011010110001100011000110001100011000110001100011000110001100011000110101100011000110001100011000\n",
      "Truth:     0011000110001100011000110001100011000110001100011000110001100011000110001100011000110001100011000110\n",
      "\n",
      "Accuracy: 0.9791666666666666, Shift: -4\n",
      "Predicted: 0011000000000000000000000000000000000000100000000000000000000000000000100000000000000000000000000000\n",
      "Truth:     0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "\n",
      "Accuracy: 1.0, Shift: -3\n",
      "Predicted: 1000010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010000\n",
      "Truth:     0010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010000100\n",
      "\n",
      "Accuracy: 0.8865979381443299, Shift: -3\n",
      "Predicted: 1101011111111111011111111111111111111111111110101111111111111011111111101011110101111111100111111111\n",
      "Truth:     1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "\n",
      "Accuracy: 0.9696969696969697, Shift: 1\n",
      "Predicted: 1011010110101001011010110101101011010110100101011010010101101011010110101101011010110101101011010110\n",
      "Truth:     0101101011010110101101011010110101101011010110101101011010110101101011010110101101011010110101101011\n",
      "\n",
      "Accuracy: 0.9489795918367347, Shift: -2\n",
      "Predicted: 1000010000101001000010000100001000010000100011000010000101001000010100100001000010000110001000010000\n",
      "Truth:     0001000010000100001000010000100001000010000100001000010000100001000010000100001000010000100001000010\n",
      "\n",
      "Accuracy: 0.92, Shift: 0\n",
      "Predicted: 1100110001110011100111001110111100111001110011100101101110011100110001110010100110001110011100011001\n",
      "Truth:     1100111001110011100111001110011100111001110011100111001110011100111001110011100111001110011100111001\n",
      "\n",
      "Accuracy: 0.97, Shift: 0\n",
      "Predicted: 1001010010100101001010110000101001010010100101001010010100101001010010100101001110010100101001010010\n",
      "Truth:     1001010010100101001010010100101001010010100101001010010100101001010010100101001010010100101001010010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_data):\n",
    "    completion = noisy_completions[i]\n",
    "    preds = np.array([int(x) for x in completion.choices[0].message.content.split()])\n",
    "    truth = np.array([int(x) for x in noisy_sequence_sets[i][1].split()])\n",
    "    acc, shift = best_shifted_acc(preds, truth)\n",
    "    print(f\"Accuracy: {acc}, Shift: {shift}\")\n",
    "    predstr = \"\".join([str(x) for x in preds])\n",
    "    truthstr = \"\".join([str(x) for x in truth])\n",
    "    print(f\"Predicted: {predstr}\")\n",
    "    print(f\"Truth:     {truthstr}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
