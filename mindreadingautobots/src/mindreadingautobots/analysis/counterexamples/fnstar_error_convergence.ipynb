{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will study the convergence and \"error bars\" for the accuracy of $f_N^*$, the optimal function for noisy inputs, by evaluating these functions on finite datasets.\n",
    "\n",
    "The current experiment for counterexamples trains an SAN to find the lowest error function on a training (or validation!) set, call this $\\hat{f}_{train}$ or $\\hat{f}_{test}$. The definition of $\\hat{f}_{test}$ is that it minimizes error on a _specific_ test set, call it $D_N$ where $N$ is the number of data. This immediately gives two statistical fluctuations:\n",
    " 1. For different $D_N$, we get different $\\hat{f}_{test}$\n",
    " 2. Any specific $\\hat{f}_{test}$ will achieve different accuracies when evaluated on different $D_N$\n",
    "\n",
    "We want to show the (error, sensitivity) point that $\\hat{f}_{test}$ is _attracted towards_. What does this mean? Suppose that we have a function $h$ that we are computing (error, sens) for.\n",
    " - this coordinate should be(?) specific for the dataset: $\\hat{f}$ cannot \"see\" alternative datasets.\n",
    " - This coordinate could therefore be the error of the $h$ that achieves optimal performance on $D_N$\n",
    " - This coordinate _might not_ be the same as the coordinate for $f_N^*$\n",
    " - A plausible choice for $h$ should be the optimal function for the specific dataset Matheus is looking at\n",
    " - **problem**: Every time i resample a dataset, I might get a pretty different sensitivity. **however** I expect all of these sensitivities to be smaller than sens of $f$, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindreadingautobots.sequence_generators import make_datasets, data_io\n",
    "import numpy as np\n",
    "from mindreadingautobots.entropy_and_bayesian import boolean\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counterexample = \"00100110\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true sensitivity: 3.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_bitflip = .2\n",
    "n_train = 10000\n",
    "signature = (0, 0, 0, 1, 1, 0, 0, 0, 0)\n",
    "n_bits = len(signature) - 1  # n_bits is total number of bits in X, not including the label\n",
    "subseq_idx = list(range(n_bits)) # for this exercise, we don't want/need subsets\n",
    "signature = dict(zip(range(len(signature)), signature))\n",
    "k = n_bits\n",
    "\n",
    "all_bitstrings = np.array(list(itertools.product([0, 1], repeat=n_bits)))\n",
    "true_func = lambda x: signature[sum(x)]\n",
    "true_sens = boolean.average_sensitivity(true_func, all_bitstrings)\n",
    "print(f\"true sensitivity: {true_sens}\")\n",
    "# seed = 1234\n",
    "\n",
    "err_memorize_Ztrain_arr = []\n",
    "sens_memorize_Ztrain_arr = []\n",
    "for seed in list(1234 + np.arange(10)):\n",
    "    # sample a variety of \"training performances\"\n",
    "    # this loop will find the f* point for the training data. To do it for the test data, we just re-run with the num data equal to val size\n",
    "    X, Z, subseq_idx = make_datasets.sparse_boolean_weightbased_k_n(n_bits + 1, k, n_train, signature, p_bitflip=p_bitflip, seed=seed, subseq_idx=subseq_idx)\n",
    "    f_lookup_on_Z, lookup_table_on_Z = boolean.dataset_lookup_table(Z)\n",
    "    f_lookup_on_X, lookup_table_on_X = boolean.dataset_lookup_table(X)\n",
    "    err_memorize_Ztrain_evaluate_Ztrain = 1 - boolean.compute_acc_on_dataset(f_lookup_on_Z, Z)\n",
    "    sens_memorize_Ztrain = boolean.average_sensitivity(f_lookup_on_Z, all_bitstrings)\n",
    "\n",
    "    err_memorize_Ztrain_arr.append(err_memorize_Ztrain_evaluate_Ztrain)\n",
    "    sens_memorize_Ztrain_arr.append(sens_memorize_Ztrain)\n",
    "    # training_data_memorization_X_err = 1 - boolean.compute_acc_on_dataset(f_lookup_on_Z, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3642000000000537, 0.36210000000005393, 0.36640000000005346, 0.3596000000000542, 0.3649000000000536, 0.37180000000005287, 0.3632000000000538, 0.3681000000000533, 0.3650000000000536, 0.36550000000005356]\n",
      "[3.015625, 2.890625, 3.0625, 2.875, 2.859375, 2.96875, 3.0625, 3.0625, 3.0, 2.984375]\n"
     ]
    }
   ],
   "source": [
    "print(err_memorize_Ztrain_arr)\n",
    "print(sens_memorize_Ztrain_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92578125"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean.compute_acc_test(f_lookup, true_func, n_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
